\documentclass[letterpaper]{article}
\usepackage[a4paper, total={7in, 8in}]{geometry}

\usepackage{xcolor}
\usepackage{Sweavel}
\usepackage{graphicx}
\def\Sweavesize{\normalsize}
% Uncomment some of the following to use some alternatives:
\def\Rcolor{\color{black}}
\def\Routcolor{\color{blue}}
\def\Rcommentcolor{\color{blue}}
\definecolor{babyblueeyes}{rgb}{0.74, 0.83, 0.95}

% To change background color or R code and/or output, use e.g.:
\def\Rbackground{\color{babyblueeyes}}
\def\Routbackground{\color[gray]{.8}}

% To use rgb specifications use \color[rgb]{ , , }
% To use gray scale use e.g. \color[gray]{0.5}
% If you change any of these after the first chunk is produced, the
% changes will have effect only for the next chunk.

\title{TOT Cued Recall Analysis}
\author{Abhilasha Kumar}

\begin{document}
\SweaveOpts{concordance=FALSE}

 \maketitle

\section{Reading the Data File}

We first read the file into an object called TOTcuedrecall. We can also display some part of the data by calling the head() function.

<<>>=
TOTcuedrecall = read.csv("Compiled_TOTCuedRecall.csv",
                         header = TRUE, sep = ",")
head(TOTcuedrecall[,c(1,21,22)])
@

\section {Conditional Target Accuracy}

In this section, we calculate the number of trials in which participants correctly or incorrectly recalled the item, and split that by whether they correctly recalled the target from the definition. Then, we calculate the proportion of trials from the raw number of trials.

<<>>=
library(dplyr)

cued_acc = group_by(TOTcuedrecall) %>%
  summarise_at(vars(CuedRecallAcc, TargetAccuracy), mean)

cued_acc = group_by(TOTcuedrecall, Subject, CuedRecallAcc) %>%
  summarise(recalltrials = n())

conditional_acc = group_by(TOTcuedrecall, Subject, 
                           CuedRecallAcc, TargetAccuracy) %>%
  summarise(trials = n())

merge_acc = merge(conditional_acc, cued_acc, 
                  by = c("Subject", "CuedRecallAcc"))
merge_acc$prop = merge_acc$trials/merge_acc$recalltrials
@

\section {ANOVA}

In this section, we perform a repeated measures ANOVA on our data, to see if we are indeed seeing a difference in the proportion of unsuccessful trials for failed and successful cued recall. 

<<>>=
## mergeacc has 4 rows missing
ez::ezDesign(merge_acc, Subject, TargetAccuracy)
merge_acc[101,] = c(12, 0, 0, 0, 0, 0)
merge_acc[102,] = c(17, 1, 1, 0 ,0, 0)
merge_acc[103,] = c(18, 0, 1, 0, 0, 0)
merge_acc[104,] = c(21, 0, 1, 0, 0, 0)

merge_acc$Subject = 
  as.factor(as.character(merge_acc$Subject))
merge_acc$CuedRecallAcc = 
  as.factor(as.character(merge_acc$CuedRecallAcc))
merge_acc$TargetAccuracy = 
  as.factor(as.character(merge_acc$TargetAccuracy))

merge_acc = merge_acc[order(merge_acc$Subject, merge_acc$CuedRecallAcc),]

cond_aov = aov(data = merge_acc, 
        prop ~ CuedRecallAcc*TargetAccuracy +
        Error(Subject/(CuedRecallAcc*TargetAccuracy)))
summary(cond_aov)


@

The ANOVA output tells us that the interaction term is not signiificant. We will next see this in a figure, to better understand our data.

\section {Conditional Figure}

<<fig=TRUE>>=
cond_figure = Rmisc::summarySE(merge_acc, 
                        measurevar = "prop",
                        groupvars = c("CuedRecallAcc", 
                                      "TargetAccuracy"))

library(ggplot2)
library(ggthemes)
condfigure_plot = cond_figure %>% mutate(Recall = factor(CuedRecallAcc, 
                      levels = unique(CuedRecallAcc),
                    labels = c("Failed Recall", 
                               "Successful Recall")),
                    `Target Retrieval` = factor(TargetAccuracy,
                          levels = unique(TargetAccuracy),
                       labels = c("Failed Target Retrieval", 
                            "Successful Target Retrieval")))%>%
ggplot(aes(x = Recall, y = prop, 
           fill = `Target Retrieval`, group = `Target Retrieval`))+
 geom_bar(stat = "identity", position = "dodge", width = 0.7)+
  geom_errorbar(aes(ymin=prop - ci, ymax=prop + ci), 
             width=.2, color = "gray26", 
             position = position_dodge(0.7))+
 theme_few()+
  scale_fill_wsj()+
    xlab("Cued Recall Accuracy") + ylab("Mean Proportion of Trials") + 
  ggtitle("Target Retrieval Accuracy 
          as a function of Cued Recall Accuracy")  +
   theme(axis.text = element_text(face = "bold", size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
          plot.title = element_text(face = "bold", 
                  size = rel(1.2), hjust = .5),
         strip.text.x = element_text(face = "bold", size = rel(1.4)))
condfigure_plot
@

\section*{Figure Target Accuracy Figure}

<<fig=TRUE>>=
TOTcuedrecall_fig = TOTcuedrecall
TOTcuedrecall_fig$PrimeType = "Unrelated"

TOTcuedrecall_fig$CuedRecallAccFac = ordered(as.factor(as.character(TOTcuedrecall_fig$CuedRecallAcc)), levels = c("1", "0"))


target_retrievalacc = group_by(TOTcuedrecall_fig, Subject, PrimeType,
                               CuedRecallAccFac) %>%
  summarise_at(vars(TargetAccuracy), mean)
target_rmisc = Rmisc::summarySE(target_retrievalacc, 
                      measurevar = "TargetAccuracy",
                      groupvars = c("CuedRecallAccFac", "PrimeType"))

library(ggplot2)
library(ggthemes)
target_rmisc %>% mutate(`Item Retrieval` = factor(CuedRecallAccFac, 
                                        levels = unique(CuedRecallAccFac),
                    labels = c("Retrieved", "Not Retrieved")))%>%
ggplot(aes(x = `Item Retrieval`, y = TargetAccuracy, group = PrimeType, fill = PrimeType))+
 geom_bar(stat = "identity", position = "dodge", width = 0.5,
                     color ="gray28")+
  geom_errorbar(aes(ymin = TargetAccuracy - se, ymax = TargetAccuracy + se),
                width=.05, position=position_dodge(.5)) +
  theme_few()+
  scale_fill_manual(values= c("lightgreen"))+
  xlab("Prime Retrieval") + ylab("Mean Target Accuracy") + 
ggtitle(" Experiment 5") +
  theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5, size = rel(1)),
         axis.text.x = element_text(face = "bold", size = rel(1.2)))
@


\section {Follow Up Tests}

For each subject, we will calculate a difference score for drop off in accuracy when they failed to recall the item vs. when they successfully retrieved the item.

<<>>=
# failedrecall = merge_acc %>% filter(CuedRecallAcc == "0")
# failedrecall = failedrecall[,-c(2,4,5)]
# successfulrecall = merge_acc %>% filter(CuedRecallAcc == "1")
# successfulrecall = successfulrecall[,-c(2,4,5)]
# 
# ## need to convert from long to wide: using spread
# library(tidyr)
# failed_wide = failedrecall %>%
#   spread(TargetAccuracy, prop)
# failed_wide$diff = failed_wide$`0` - failed_wide$`1`
# 
# successful_wide = successfulrecall %>%
#   spread(TargetAccuracy, prop)
# successful_wide$diff = successful_wide$`0` - successful_wide$`1`
@

Now we have two datasets, each contains a difference score for each subject, for failed and successful cued recall. Now, we can perform a paired t-test (why paired? because the data for failed and successful recall comes from the same subjects i.e., it is a within-subjects design). 

<<>>=
# t.test(failed_wide$diff, successful_wide$diff, paired = TRUE)
@


\section {HLM Model}

<<>>=
library(lme4)

## adding prime acc as a covariate

participant_acc = group_by(TOTcuedrecall, Subject) %>%
  summarise_at(vars(TargetAccuracy, CuedRecallAcc), mean)

participant_acc$MeanAcc = (participant_acc$TargetAccuracy + 
                          participant_acc$CuedRecallAcc)/2

colnames(participant_acc) = c("Subject", "TargetAcc", "PrimeAcc", "MeanAcc")

TOTCuedrecall2 = merge(TOTcuedrecall, participant_acc[,c(1,3,4)], 
                       by = c("Subject"))

TOTCuedrecall2$CuedRecallAcc = as.factor(TOTCuedrecall2$CuedRecallAcc)
lmer_model_acc = lme4::glmer(data = TOTCuedrecall2, 
                             TargetAccuracy ~ 
                           CuedRecallAcc + PrimeAcc +
                           (1|Subject) + (1|Target.Trial.),
                          family = "binomial",
                          control=glmerControl(optimizer="bobyqa",
          optCtrl=list(maxfun=100000)))
summary(lmer_model_acc)
car::Anova(lmer_model_acc)
options(contrasts = c("contr.sum","contr.poly"))
anova(lmer_model_acc)

### OLD CODE
TOTcuedrecall$TargetAccuracy = as.factor(TOTcuedrecall$TargetAccuracy)
TOTcuedrecall$CuedRecallAcc = as.factor(TOTcuedrecall$CuedRecallAcc)

TOTcuedrecall$FailedRetrieval = ifelse(TOTcuedrecall$TargetAccuracy == 1,0,1)

totcuedrecall_hlm = glmer(data = TOTcuedrecall, TargetAccuracy ~ CuedRecallAcc +
                        (1|Subject), family = "binomial")
summary(totcuedrecall_hlm)
car::Anova(totcuedrecall_hlm)


@

\subsubsection{Plot}

<<fig=TRUE>>=
fixed.frame <- 
  data.frame(expand.grid( CuedRecallAcc = c("0","1"))) %>%
  mutate(pred = predict(totcuedrecall_hlm, newdata = ., re.form = NA))

fixed.frame$odds = exp(fixed.frame$pred)
fixed.frame$prob = fixed.frame$odds/(1+ fixed.frame$odds)

fixed.frame$failure = 1 - fixed.frame$prob



fixed.frame %>% 
  mutate(CuedRecallAccuracy = factor(CuedRecallAcc, 
    levels = unique(CuedRecallAcc),
                    labels = c("Failed Recall", "Successful Recall")))%>%
ggplot(aes(x = CuedRecallAccuracy, y = prob))+
  geom_line(group = 1)+
# geom_bar(stat = "identity", position = "dodge", 
 #         width = 0.7, color = "black")+
 theme_few()+
  xlab("Cued Recall Accuracy") + ylab("Probability of Failing at Target Retrieval") + 
  ggtitle("TOT Cued Recall ")  +
   theme(axis.text = element_text(face = "bold", size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
     plot.title = element_text(face = "bold", size = rel(1.5), hjust = .5),
         strip.text.x = element_text(face = "bold", size = rel(1.4)))

@

\section {z-scoring RTs}
\subsection*{RT prime and Target}

<<>>=
library(dplyr)
colnames(TOTcuedrecall) = c("Subject", "Session", "Procedure", "Trial", 
                            "Prime", "PrimeDefResp",
                            "PrimeDefRT", "Cue","PrimeLength",
                            "PrimeResp", "PrimeRespRT", "Stimuli1",
                            "StimuliNo",
                           "Target", "TargetDefResp", "TargetDefRT",
                            "State", "StateRT", "TargetResp", "TargetRespRT",
                            "CuedRecallAcc", "Accuracy",  
                            "RTrecognisePrime", "RTrecogniseTarget",
                           "FailedRetrieval")

TOTcuedrecall_firsttrim_target = subset(TOTcuedrecall, 
                                 TOTcuedrecall$RTrecogniseTarget > 250 &
                                TOTcuedrecall$RTrecogniseTarget < 7000)

TOTcuedrecall_firsttrim_prime = subset(TOTcuedrecall, 
                                 TOTcuedrecall$RTrecognisePrime > 250 &
                                TOTcuedrecall$RTrecognisePrime < 7000)

TOTcuedrecall_firsttrim_targetdef = subset(TOTcuedrecall, 
                                 TOTcuedrecall$TargetDefRT > 250 &
                                TOTcuedrecall$TargetDefRT < 9000)

@ 

\subsection*{RTRecogniseprime}

<<>>=
## FOR PRIME
## aggregate per subject all IVs and DVs
meanRT = group_by(TOTcuedrecall_firsttrim_prime, Subject) %>%
  summarise_at(vars(RTrecognisePrime), mean)
colnames(meanRT) = c("Subject", 
                     "MeanRTrecogPrime")

sdRT = group_by(TOTcuedrecall_firsttrim_prime, Subject) %>%
  summarise_at(vars(RTrecognisePrime), sd)
colnames(sdRT) = c("Subject",
                     "sdRTrecogPrime")

RT_agg = merge(meanRT, sdRT, by = "Subject")

## merge aggregate info with long data
TOTcuedrecall_z_prime = merge(TOTcuedrecall_firsttrim_prime, 
                             RT_agg, by = "Subject", all.x = T)

## person and grand-mean centered scores using original and aggregate
library(dplyr)
TOTcuedrecall_z_prime = TOTcuedrecall_z_prime %>% mutate(zPrimeRecogRT = 
                                             (RTrecognisePrime - 
                                                MeanRTrecogPrime)/sdRTrecogPrime)
                 
## checking: subject level means should be zero

sub_pic = group_by(TOTcuedrecall_z_prime, Subject) %>%
  summarise_at(vars(zPrimeRecogRT), mean)
@

\subsection*{RTRecogniseTarget}
<<>>=
## FOR TARGET
## aggregate per subject all IVs and DVs
meanRT = group_by(TOTcuedrecall_firsttrim_target, Subject) %>%
  summarise_at(vars(RTrecogniseTarget), mean)
colnames(meanRT) = c("Subject", "MeanRTrecogTarget")

sdRT = group_by(TOTcuedrecall_firsttrim_target, Subject) %>%
  summarise_at(vars(RTrecogniseTarget), sd)
colnames(sdRT) = c("Subject", "sdRTrecogTarget")

RT_agg = merge(meanRT, sdRT, by = "Subject")

## merge aggregate info with long data
TOTcuedrecall_z_target= merge(TOTcuedrecall_firsttrim_target,
                             RT_agg, by = "Subject", all.x = T)

## person and grand-mean centered scores using original and aggregate
library(dplyr)
TOTcuedrecall_z_target = TOTcuedrecall_z_target %>% mutate( zTargetRecogRT = 
                                             (RTrecogniseTarget - 
                                                MeanRTrecogTarget)/sdRTrecogTarget)
                 
## checking: subject level means should be zero

sub_pic = group_by(TOTcuedrecall_z_target, Subject) %>%
  summarise_at(vars(zTargetRecogRT), mean)

@

\subsection*{TargetDefRT}
<<>>=
## FOR TARGET
## aggregate per subject all IVs and DVs
meanRT = group_by(TOTcuedrecall_firsttrim_targetdef, Subject) %>%
  summarise_at(vars(TargetDefRT), mean)
colnames(meanRT) = c("Subject", "MeanTargetRT")

sdRT = group_by(TOTcuedrecall_firsttrim_targetdef, Subject) %>%
  summarise_at(vars(TargetDefRT), sd)
colnames(sdRT) = c("Subject", "sdTargetRT")

RT_agg = merge(meanRT, sdRT, by = "Subject")

## merge aggregate info with long data
TOTcuedrecall_z_targetdef = merge(TOTcuedrecall_firsttrim_targetdef,
                             RT_agg, by = "Subject", all.x = T)

## person and grand-mean centered scores using original and aggregate
library(dplyr)
TOTcuedrecall_z_targetdef = TOTcuedrecall_z_targetdef %>% mutate( zTargetRT = 
                                             (TargetDefRT - 
                                                MeanTargetRT)/sdTargetRT)
                 
## checking: subject level means should be zero

sub_pic = group_by(TOTcuedrecall_z_targetdef, Subject) %>%
  summarise_at(vars(zTargetRT), mean)

@

\section {Trimming z-RTs}

<<>>=

TOTcuedrecall_z_trimmed_prime = subset(TOTcuedrecall_z_prime, 
                                TOTcuedrecall_z_prime$zPrimeRecogRT < 3 & 
                                  TOTcuedrecall_z_prime$zPrimeRecogRT > -3)

TOTcuedrecall_z_trimmed_target = subset(TOTcuedrecall_z_target, 
                                TOTcuedrecall_z_target$zTargetRecogRT < 3 & 
                                  TOTcuedrecall_z_target$zTargetRecogRT > -3)

TOTcuedrecall_z_trimmed_targetdef = subset(TOTcuedrecall_z_targetdef, 
                                TOTcuedrecall_z_targetdef$zTargetRT < 3 & 
                                  TOTcuedrecall_z_targetdef$zTargetRT > -3)
@

\section {Repeating z-scoring}

\subsection{For prime}

<<>>=
## aggregate per subject all IVs and DVs
meanRT_prime = group_by(TOTcuedrecall_z_trimmed_prime, Subject) %>%
  summarise_at(vars(RTrecognisePrime), mean)
colnames(meanRT_prime) = c("Subject", 
                     "MeanRTrecogPrime_trim")

sdRT_prime = group_by(TOTcuedrecall_z_trimmed_prime, Subject) %>%
  summarise_at(vars(RTrecognisePrime), sd)
colnames(sdRT_prime) = c("Subject",
                     "sdRTrecogPrime_trim")

RT_agg_prime = merge(meanRT_prime, sdRT_prime, by = "Subject")

## merge aggregate info with long data
TOTcuedrecall_final_z_prime = merge(TOTcuedrecall_z_trimmed_prime, 
                             RT_agg_prime, by = "Subject", all.x = T)

## person and grand-mean centered scores using original and aggregate
library(dplyr)
TOTcuedrecall_final_z_prime = TOTcuedrecall_final_z_prime %>% 
                                  mutate( zPrimeRecogRT_trim = 
                                             (RTrecognisePrime - 
                                      MeanRTrecogPrime_trim)/sdRTrecogPrime_trim)
                 
## checking: subject level means should be zero

sub_pic = group_by(TOTcuedrecall_final_z_prime, Subject) %>%
  summarise_at(vars(zPrimeRecogRT_trim), mean)

@

\subsection{For Target}

<<>>=
## aggregate per subject all IVs and DVs
meanRT_target = group_by(TOTcuedrecall_z_trimmed_target, Subject) %>%
  summarise_at(vars(RTrecogniseTarget), mean)
colnames(meanRT_target) = c("Subject", 
                     "MeanRTrecogTarget_trim")

sdRT_target = group_by(TOTcuedrecall_z_trimmed_target, Subject) %>%
  summarise_at(vars(RTrecogniseTarget), sd)
colnames(sdRT_target) = c("Subject", 
                      "sdRTrecogTarget_trim")

RT_agg_target = merge(meanRT_target, sdRT_target, by = "Subject")

## merge aggregate info with long data
TOTcuedrecall_final_z_target = merge(TOTcuedrecall_z_trimmed_target, 
                             RT_agg_target, by = "Subject", all.x = T)

## person and grand-mean centered scores using original and aggregate
library(dplyr)
TOTcuedrecall_final_z_target = TOTcuedrecall_final_z_target %>% 
                                  mutate( zTargetRecogRT_trim = 
                                             (RTrecogniseTarget - 
                                      MeanRTrecogTarget_trim)/sdRTrecogTarget_trim)
                 
## checking: subject level means should be zero

sub_pic = group_by(TOTcuedrecall_final_z_target, Subject) %>%
  summarise_at(vars(zTargetRecogRT_trim), mean)

@

\subsection{For TargetDefRT}

<<>>=
## aggregate per subject all IVs and DVs
meanRT_targetdef = group_by(TOTcuedrecall_z_trimmed_targetdef, Subject) %>%
  summarise_at(vars(TargetDefRT), mean)
colnames(meanRT_targetdef) = c("Subject", "MeanTargetRT_trim")

sdRT_targetdef = group_by(TOTcuedrecall_z_trimmed_targetdef, Subject) %>%
  summarise_at(vars(TargetDefRT), sd)
colnames(sdRT_targetdef) = c("Subject", "sdTargetRT_trim")

RT_agg_targetdef = merge(meanRT_targetdef, sdRT_targetdef, by = "Subject")

## merge aggregate info with long data
TOTcuedrecall_final_z_targetdef = merge(TOTcuedrecall_z_trimmed_targetdef, 
                             RT_agg_targetdef, by = "Subject", all.x = T)

## person and grand-mean centered scores using original and aggregate
library(dplyr)
TOTcuedrecall_final_z_targetdef = TOTcuedrecall_final_z_targetdef %>% 
                                  mutate(zTargetRT_trim = 
                                             (TargetDefRT - 
                                                MeanTargetRT_trim)/sdTargetRT_trim)
                 
## checking: subject level means should be zero

sub_pic = group_by(TOTcuedrecall_final_z_targetdef, Subject) %>%
  summarise_at(vars(zTargetRT_trim), mean)

@

\subsection {Combining z-RT Prime and Target }

<<>>=
## now we have separately z-scored RTprime and RTtarget. Need to combine.
## taking only necessary columns
TOTcuedrecall_final_z_prime2 = TOTcuedrecall_final_z_prime[,c(1,4,31)]

TOTcuedrecall_final_z = merge(TOTcuedrecall_final_z_target, 
                             TOTcuedrecall_final_z_prime2, 
                             by  = c("Subject", "Trial"))

primefinal_z_targetdef = merge(TOTcuedrecall_final_z_targetdef, 
                             TOTcuedrecall_final_z_prime2, 
                             by  = c("Subject", "Trial"))
@

\section {Linear Models}

<<fig=TRUE>>=
# Mean RT to retrieve Target as a function of Prime Condition

# Effect of RT prime on Accuracy
TOTcuedrecall_final_z = TOTcuedrecall_final_z %>%
                          filter(!Subject %in% c(1))
library(lme4)
RTprime_acc_model = glmer(data = TOTcuedrecall_final_z, 
                          Accuracy ~ zPrimeRecogRT_trim + 
                            (1|Subject) + (1|Target), family = binomial )
summary(RTprime_acc_model)
car::Anova(RTprime_acc_model)
options(contrasts = c("contr.sum","contr.poly"))
anova(RTprime_acc_model)

RTprime_RT_model = lmer(data = TOTcuedrecall_final_z, 
                    zTargetRecogRT_trim ~ zPrimeRecogRT_trim + 
                            (1|Subject) + (1|Target))
summary(RTprime_RT_model)
car::Anova(RTprime_RT_model)
options(contrasts = c("contr.sum","contr.poly"))
anova(RTprime_RT_model)

@

\section {Plotting Model Fits}
\subsection {Model 1}
<<fig=TRUE>>=
fixed.frame <- 
  data.frame(expand.grid(zPrimeRecogRT_trim = seq(-3,3,0.5)))%>%
  mutate(pred = predict(RTprime_acc_model, newdata = ., re.form = NA))

fixed.frame$odds = exp(fixed.frame$pred)
fixed.frame$prob = fixed.frame$odds/(1+fixed.frame$odds)

fixed.frame %>%
  ggplot(aes(x = zPrimeRecogRT_trim, y = prob)) +
    geom_line(size = 1, color = "blue") + 
    ylim(0.10,0.40)+
    xlab("z-RT to Demask Prime") + ylab ("Mean Target Accuracy")+ 
  ggtitle("Model Fit: Target Accuracy by Prime Demasking RT")+
theme_few() +
    theme(axis.text = element_text(face = "bold", size = rel(1.2)),
          axis.title = element_text(face = "bold", size = rel(1.2)),
          legend.title = element_text(face = "bold", size = rel(1.2)),
          plot.title = element_text(face = "bold", size = rel(1.2), hjust = .5))
@


\subsection {RT Model}

<<fig=TRUE>>=
TOTcuedrecall_final_z$Accuracy = as.numeric(as.character(TOTcuedrecall_final_z$Accuracy))
TOTcuedrecall_final_z1 = TOTcuedrecall_final_z %>% filter(Subject != "6")
TOTcuedrecall_final_z1$PrimeCondition = "U"
mainplot = TOTcuedrecall_final_z1 %>%
 ggplot(aes(x =zPrimeRecogRT_trim , y = zTargetRecogRT_trim, 
             group = factor(Subject))) +
  geom_smooth(method = "lm", se = FALSE, color = "white", size = 0.5)+
  guides(color = FALSE)+
  #facet_wrap(~PrimeCondition)+
    xlab("z-RT to Demask Prime") + ylab ("z-RT to Demask Target")+ 
  ggtitle("Experiment 5")+
theme_few() +
     theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5, size = rel(1)),
         axis.text.x = element_text(face = "bold", size = rel(1.2)))

mainplot + stat_smooth(aes(group = 1), method = "lm", color = "lightgreen", se = FALSE)

@

\subsection {Acc Model}

<<fig=TRUE>>=


mainplot = TOTcuedrecall_final_z1 %>%
 ggplot(aes(x =zPrimeRecogRT_trim , y = Accuracy, 
             group = factor(Subject))) +
  geom_smooth(method = "lm", se = FALSE, color = "white", size = 0.5)+
  guides(color = FALSE)+
    xlab("z-RT to Demask Prime") + ylab ("Mean Target Accuracy")+ 
  ggtitle("")+
theme_few() +
     theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5, size = rel(1)),
         axis.text.x = element_text(face = "bold", size = rel(1.2)))

mainplot + stat_smooth(aes(group = 1), method = "lm", color = "lightgreen", se = FALSE)

@


\end{document}
