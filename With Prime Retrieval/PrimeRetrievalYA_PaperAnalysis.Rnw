\documentclass[a4paper]{article}
\usepackage{Sweave}
\usepackage{fixltx2e}

\usepackage[margin=1.0in]{geometry}

 \DefineVerbatimEnvironment{Sinput}{Verbatim} { frame = lines, fontshape = sl}
\DefineVerbatimEnvironment{Soutput}{Verbatim}{frame=lines, fontshape = sl}

\title{Prime Retrieval Study: Analysis}
\author{Abhilasha Kumar}
<<echo=FALSE>>=
options(width=60)
library(xtable)
library(ggplot2)
library(ggthemes)
library(gridExtra)
library(tidyr)
library(sjPlot)
@

<<>>=
sjp.setTheme(base = theme_few())
@
\begin{document}
\SweaveOpts{concordance=TRUE}
 \maketitle

\section{Reading File}

<<>>=
PrimeRetrieval <- read.csv("CompleteYAOA_FINAL.csv", 
                           header = TRUE, sep = ",")
library(dplyr)
PrimeRetrieval = PrimeRetrieval %>% filter(AgeGroup == "Young")
@

\section {Prime And Target Accuracy}
<<>>=
library(dplyr)

agg_condition <- group_by(PrimeRetrieval, PrimeCondition)%>%
    summarise_at(vars(Accuracy), mean)

agg_sub_condition <-  group_by(PrimeRetrieval, Subject, PrimeCondition)%>%
    summarise_at(vars(Accuracy), mean)

agg_sub_condition$Subject <- as.factor(agg_sub_condition$Subject)
agg_sub_condition$PrimeCondition <- as.factor(agg_sub_condition$PrimeCondition)

agg_sub_prime = group_by(PrimeRetrieval, Subject, PrimeCondition) %>%
   summarise_at(vars(PrimeFirstResp_ACC), mean)
## target accuracy anova

prime_aov = aov(data = agg_sub_condition, Accuracy ~ PrimeCondition + 
                                        Error(Subject/PrimeCondition))
summary(prime_aov)

## prime accuracy anova
agg_sub_prime$Subject = as.factor(agg_sub_prime$Subject)
primeaccuracy_aov = aov(data = agg_sub_prime, 
                        PrimeFirstResp_ACC ~ PrimeCondition + 
                                        Error(Subject/PrimeCondition))
summary(primeaccuracy_aov)

## specific t-tests
prime_p = agg_sub_prime %>% filter(PrimeCondition == "P")
prime_r = agg_sub_prime %>% filter(PrimeCondition == "R")
prime_b = agg_sub_prime %>% filter(PrimeCondition == "B")
prime_u = agg_sub_prime %>% filter(PrimeCondition == "U")

t.test(prime_p$PrimeFirstResp_ACC, prime_r$PrimeFirstResp_ACC, paired = TRUE)
t.test(prime_p$PrimeFirstResp_ACC, prime_b$PrimeFirstResp_ACC, paired = TRUE)
t.test(prime_p$PrimeFirstResp_ACC, prime_u$PrimeFirstResp_ACC, paired = TRUE)

t.test(prime_b$PrimeFirstResp_ACC, prime_r$PrimeFirstResp_ACC, paired = TRUE)
t.test(prime_b$PrimeFirstResp_ACC, prime_u$PrimeFirstResp_ACC, paired = TRUE)
t.test(prime_r$PrimeFirstResp_ACC, prime_u$PrimeFirstResp_ACC, paired = TRUE)

## accounting for mean accuracy

participant_acc = group_by(PrimeRetrieval, Subject) %>%
  summarise_at(vars(Accuracy, PrimeFirstResp_ACC), mean)

participant_acc$MeanAcc = (participant_acc$Accuracy + 
                          participant_acc$PrimeFirstResp_ACC)/2

median_acc = median(participant_acc$MeanAcc)


colnames(participant_acc) = c("Subject", "TargetAcc", "PrimeAcc", "MeanAcc")

PrimeRetrieval = merge(PrimeRetrieval, participant_acc[,c(1,3,4)], 
                       by = c("Subject"))
@

\section {Good Bad subjects}

<<>>=
PrimeRetrieval_Perform = PrimeRetrieval

PrimeRetrieval_Perform$Performance = ifelse(PrimeRetrieval_Perform$MeanAcc <= median_acc, "Low Performer", "High Performer")

PrimeRetrieval_Perform$Performance = as.factor(PrimeRetrieval_Perform$Performance)

PrimeRetrieval_fig1 = PrimeRetrieval_Perform
PrimeRetrieval_fig1$primefac = ordered(as.factor(as.character(PrimeRetrieval_fig1$PrimeCondition)), levels = c("B", "R", "P", "U"))

PrimeRetrieval_fig1$PrimeFirstResp_ACC_fac = ordered(as.factor(as.character(PrimeRetrieval_fig1$PrimeFirstResp_ACC)), levels = c("1", "0"))

agg_sub_ya1 = group_by(PrimeRetrieval_fig1, Subject, Performance, primefac,
                       PrimeFirstResp_ACC_fac) %>%
  summarise_at(vars(Accuracy), mean)

agg_prime_ya1= Rmisc::summarySE(agg_sub_ya1, 
                      measurevar = "Accuracy",
                      groupvars = c("Performance",
                        "PrimeFirstResp_ACC_fac", "primefac"))

library(ggplot2)
library(ggthemes)


agg_prime_ya1 %>% mutate(PrimeType = factor(primefac, 
                                        levels = unique(primefac),
                    labels = c("Both","Semantic", "Phonological",
                                "Unrelated")),
                    `Prime Retrieval` = factor(PrimeFirstResp_ACC_fac, 
                                levels = unique(PrimeFirstResp_ACC_fac),
                    labels = c("Retrieved", "Not Retrieved")))%>%
  ggplot(aes(x = `Prime Retrieval`, y = Accuracy, 
                          group =PrimeType , 
                          fill = PrimeType)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.5,
           color ="gray28")+
   geom_errorbar(aes(ymin = Accuracy - se, 
                     ymax = Accuracy + se),
                width=.08, position=position_dodge(.5)) +
  theme_few()+
  facet_wrap(~Performance)+
#  scale_fill_canva()+
 scale_fill_manual(values = c( "lightsalmon", "red",
                               "paleturquoise3","lightgreen"))+       
  xlab("Prime Retrieval") + ylab("Mean Target Accuracy") + 
ggtitle(" Experiment 3") +
  theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5, size = rel(1)),
        strip.text.x = element_text(hjust = .5, size = rel(1.5)),
         axis.text.x = element_text(face = "bold", size = rel(1.2)))

PrimeRetrieval_fig1$Relationship = ifelse(PrimeRetrieval_fig1$PrimeCondition %in% 
                                       c("B", "R"), "Meaning", "NotMeaning")
PrimeRetrieval_fig1$Relationship = as.factor(PrimeRetrieval_fig1$Relationship)

e3_ret_notret_agg1 = group_by(PrimeRetrieval_fig1, Subject, Performance,
                              Relationship,
                             PrimeFirstResp_ACC) %>%
  summarise_at(vars(Accuracy), mean)
e3_ret_notret_agg1$Subject = as.factor(e3_ret_notret_agg1$Subject)


meaning = e3_ret_notret_agg1 %>% filter(Relationship == "Meaning")
notmeaning = e3_ret_notret_agg1 %>% filter(Relationship == "NotMeaning")
meaning_ret = meaning %>% filter(PrimeFirstResp_ACC == "1")
meaning_notret = meaning %>% filter(PrimeFirstResp_ACC == "0")

notmeaning_ret = notmeaning %>% filter(PrimeFirstResp_ACC == "1")
notmeaning_notret = notmeaning %>% filter(PrimeFirstResp_ACC == "0")

meaning_ret_high = meaning_ret %>% filter(Performance == "High Performer")
notmeaning_ret_high = notmeaning_ret %>% filter(Performance == "High Performer")

t.test(meaning_ret_high$Accuracy, notmeaning_ret_high$Accuracy, paired = TRUE)

meaning_ret_low = meaning_ret %>% filter(Performance == "Low Performer")
notmeaning_ret_low = notmeaning_ret %>% filter(Performance == "Low Performer")
t.test(meaning_ret_low$Accuracy, notmeaning_ret_low$Accuracy, paired = TRUE)

meaning_notret_high = meaning_notret %>% filter(Performance == "High Performer")
notmeaning_notret_high = notmeaning_notret %>% filter(Performance == "High Performer")

t.test(meaning_notret_high$Accuracy, notmeaning_notret_high$Accuracy, paired = TRUE)

meaning_notret_low = meaning_notret %>% filter(Performance == "Low Performer")
notmeaning_notret_low = notmeaning_notret %>% filter(Performance == "Low Performer")
t.test(meaning_notret_low$Accuracy, notmeaning_notret_low$Accuracy, paired = TRUE)

@

\section {Effect of Prime Retrieval}

<<>>=
PrimeRetrieval$PrimeFirstResp_ACC <- as.factor(as.character(PrimeRetrieval$PrimeFirstResp_ACC))
PrimeRetrieval$PrimeFirstResp_ACC = ifelse(PrimeRetrieval$PrimeFirstResp_ACC == "0", "Not Retrieved", "Retrieved")
PrimeRetrieval$PrimeFirstResp_ACC <- as.factor(as.character(PrimeRetrieval$PrimeFirstResp_ACC))

agg_target_correct = group_by(PrimeRetrieval, Subject, Accuracy)%>%
    summarise(n = n())
colnames(agg_target_correct) = c("Subject", "TargetAccuracy", "TargetTrials")

agg_prime_correct = group_by(PrimeRetrieval, Subject, 
                                    PrimeFirstResp_ACC)%>%
    summarise(n = n())
colnames(agg_prime_correct) = c("Subject", "PrimeRetrieved", "PrimeTrials")

agg_primeret_alltrials = group_by(PrimeRetrieval, Subject, MeanAcc, PrimeAcc,
                            PrimeFirstResp_ACC, Accuracy)%>%
    summarise(n = n())
colnames(agg_primeret_alltrials) = c("Subject", "MeanAcc", "PrimeAcc",
                                     "PrimeRetrieved", 
                                     "TargetAccuracy", "Trials")

##ALL TRIALS

merged_agg_primeret_all = merge(agg_target_correct, agg_primeret_alltrials, 
                                by = c("Subject", "TargetAccuracy"))


# NOTE: SUBJECT 20 has an empty cell for Not Retrieved i.e. there were no trials where they correctly retrieved the target but did not correctly retrieve the prime. 
merged_agg_primeret_all[192, ] = c("20","1", "10", "0.3680556", "0.5972222",
                                   "Not Retrieved", 0)
                                   

merged_agg_primeret_all = merge(merged_agg_primeret_all, agg_prime_correct,
                                by = c("Subject", "PrimeRetrieved") )
merged_agg_primeret_all$Trials = as.numeric(as.character(merged_agg_primeret_all$Trials))

merged_agg_primeret_all$TargetTrials = as.numeric(as.character(merged_agg_primeret_all$TargetTrials))

merged_agg_primeret_all$ProportionTarget = merged_agg_primeret_all$Trials/
  merged_agg_primeret_all$TargetTrials

merged_agg_primeret_all$ProportionPrime = merged_agg_primeret_all$Trials/
  merged_agg_primeret_all$PrimeTrials

merged_agg_primeret_all$Subject = as.factor(as.character(merged_agg_primeret_all$Subject)) 
merged_agg_primeret_all$TargetAccuracy = as.factor(as.character(merged_agg_primeret_all$TargetAccuracy)) 
merged_agg_primeret_all$MeanAcc = as.numeric(as.character(merged_agg_primeret_all$MeanAcc))

merged_agg_primeret_all$PrimeAcc = as.numeric(as.character(merged_agg_primeret_all$PrimeAcc))


primeret_aov = aov(data = merged_agg_primeret_all, 
                   ProportionPrime ~ TargetAccuracy*PrimeRetrieved + 
                          Error(Subject/(TargetAccuracy*PrimeRetrieved)))

summary(primeret_aov)

### LM with Prime Accuracy as a covariate

## in agg data: 3 way not sig: IMPORTANT! It is not the case
## that good subjects are driving this pattern

library(lme4)
library(lmerTest)
model_acc = lmer(data = merged_agg_primeret_all, 
                 ProportionPrime ~ TargetAccuracy*PrimeRetrieved*PrimeAcc +
                   (1|Subject))
summary(model_acc)
@

\subsection {Model Acc Plotting}
<<fig=TRUE>>=
fixed.frame <- merged_agg_primeret_all %>% 
  dplyr::summarise(mean = mean(PrimeAcc, na.rm = T), 
            sd = sd(PrimeAcc, na.rm = T))

fixed.frame <-
  data.frame(
    expand.grid(
      # here, you add values for your time variable and predictors
      TargetAccuracy = c("0","1"),
      PrimeRetrieved = c("Not Retrieved","Retrieved"),
       PrimeAcc = c(fixed.frame$mean-fixed.frame$sd,
                     fixed.frame$mean,
                     fixed.frame$mean+fixed.frame$sd))) 

fixed.frame$pred = predict(model_acc, newdata = fixed.frame, re.form = NA)

library(ggplot2)
library(ggthemes)
fixed.frame %>%
mutate(MeanAccuracy = factor(PrimeAcc, levels = unique(PrimeAcc),
                                 labels = c("-1SD Low performing Subjects", 
                                            "0SD Mean Performing Subjects", 
                                            "1SD High Performing Subjects")),
 `Target Retrieval` = factor(TargetAccuracy, levels = unique(TargetAccuracy),
                           labels = c("Failed Retrieval", 
                                      "Successful Retrieval")),
                           `Prime Retrieval`= factor(PrimeRetrieved, 
                                  levels = unique(PrimeRetrieved),
               labels = c("Prime Not Retrieved", "Prime Retrieved")))%>% 
  ggplot(aes(x = `Prime Retrieval`, y = pred, 
             fill = `Target Retrieval`, group = `Target Retrieval`)) +
 geom_bar(stat = "identity", position = "dodge", color = "black")+
        labs(x = "Prime Retrieval", 
             y = "Proportion of Trials",
         title = "YA: Prime Retrieval by Target Accuracy") +
  facet_wrap(~MeanAccuracy)+
  theme_few()+
scale_fill_wsj()  +
  theme(axis.text = element_text(face = "bold", size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
          plot.title = element_text(face = "bold", size = rel(1), hjust = .5))
@

\section {Effect of Prime Retrieved by Prime Condition}

<<>>=
#counting number of correct and incorrect trials per prime condition:
agg_target_correct_primetype = group_by(PrimeRetrieval, Subject, 
                                        PrimeCondition, Accuracy)%>%
    summarise(n = n())
colnames(agg_target_correct_primetype) = c("Subject", "PrimeCondition",
                                           "TargetAccuracy", "TargetTrials")

agg_prime_correct_primetype = group_by(PrimeRetrieval, Subject, PrimeCondition, 
                                        PrimeFirstResp_ACC)%>%
    summarise(n = n())
colnames(agg_prime_correct_primetype) = c("Subject", "PrimeCondition",
                                           "PrimeRetrieval", "PrimeTrials")

agg_prime_target_primetype = group_by(PrimeRetrieval, Subject, PrimeCondition, 
                                        PrimeFirstResp_ACC, Accuracy)%>%
    summarise(n = n())
colnames(agg_prime_target_primetype) = c("Subject", "PrimeCondition",
                                           "PrimeRetrieval", "TargetAccuracy",
                                         "SubTrials")
merged_main = merge(agg_prime_correct_primetype,agg_prime_target_primetype,
                    by = c("Subject", "PrimeCondition", "PrimeRetrieval" ))

merged_main$Proportion = merged_main$SubTrials/merged_main$PrimeTrials

## Note: Subjects 6 and 41 have one missing cell each, we fill it up with 0 trials

agg_target_correct_primetype[383,] = c("6", "P", "1", "0")
agg_target_correct_primetype[384,] = c("41", "R", "1", "0")
## now we have the correct and incorrect trials in each prime condition. 
## We now need these trials split by ret/notret for each prime condition

maindata = group_by(PrimeRetrieval, Subject,
                    PrimeCondition, PrimeFirstResp_ACC, Accuracy)%>%
    summarise(n = n())
colnames(maindata) = c("Subject", "PrimeCondition", "PrimeRetrieval", 
                       "TargetAccuracy", "Trials")

## we merge this with agg_target_correct and agg_prime_correct to get everything in the same df

finaldata = merge(maindata, agg_target_correct_primetype, 
                  by = c("Subject", "PrimeCondition", "TargetAccuracy"))
finaldata = merge(finaldata, agg_prime_correct_primetype, 
                  by = c("Subject", "PrimeCondition", "PrimeRetrieval"))

finaldata$TargetTrials = as.numeric(as.character(finaldata$TargetTrials))
finaldata$ProportionTarget = finaldata$Trials/finaldata$TargetTrials
finaldata$ProportionPrime = finaldata$Trials/finaldata$PrimeTrials

## lot of missing data in finaldata: need 768rows have 735

ya_finalaov = lmer(data = finaldata, ProportionPrime ~ 
                     PrimeRetrieval*PrimeCondition*TargetAccuracy + 
                     (1|Subject))
car::Anova(ya_finalaov)
sjPlot::plot_model(ya_finalaov, type = "int")

@

\subsection {Using lmer}

<<>>=
#  since finaldata has several missing trials -- need 704 have 662, ANOVA is probably not the best idea -- thus, we run a linear model

contrasts(PrimeRetrieval$PrimeCondition) = contr.treatment(4, base = 1)
PrimeRetrieval$PrimeFirstResp_ACC = as.factor(PrimeRetrieval$PrimeFirstResp_ACC)
m_young_prime = lme4::glmer(data = PrimeRetrieval, Accuracy ~ 
                           PrimeFirstResp_ACC*PrimeCondition + PrimeAcc +
                           (1|Subject) + (1|Stimuli2),
                          family = "binomial",
                          control=glmerControl(optimizer="bobyqa",
            optCtrl=list(maxfun=100000)))

summary(m_young_prime)
options(contrasts = c("contr.sum","contr.poly"))
car::Anova(m_young_prime)
anova(m_young_prime)

m_young_prime2 = lme4::glmer(data = PrimeRetrieval, Accuracy ~ 
                           PrimeFirstResp_ACC*PrimeCondition +
                           (1|Subject) + (1|Stimuli2),
                          family = "binomial",
                          control=glmerControl(optimizer="bobyqa",
            optCtrl=list(maxfun=100000)))

summary(m_young_prime2)
car::Anova(m_young_prime2)

anova(m_young_prime, m_young_prime2)
@

<<>>=
x = sjPlot::plot_model(m_young_prime, type = "pred", 
                       terms = c("PrimeCondition","PrimeFirstResp_ACC"))
library(ggplot2)
library(ggthemes)
x + theme_few()+
      xlab("Prime Retrieval") + ylab("Predicted Target Accuracy") + 
ggtitle("YA: Target Retrieval ~ \nPrime Retrieval x Prime Condition") +
  theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5),
         strip.text.x = element_text(face = "bold", size = rel(1.4)))
@

\subsection {Contrast Codes}

<<>>=
groups <- read.table('groups_TOT.csv',
                     sep=',',header=TRUE,stringsAsFactors=FALSE)
groups

dummy_codes <- as.matrix(groups[,4:7])
dummy_codes

fixed_effects = matrix(fixef(m_young_prime))

means_matrix <- matrix(rep(0,64),ncol=8,nrow=8)
means_matrix[,1] <- 1
means_matrix[,2] <- dummy_codes[,1]
means_matrix[,3:5] <- dummy_codes[,2:4]
means_matrix[,6:8] <- dummy_codes[,1]*dummy_codes[,2:4]
means_matrix

means <- means_matrix %*% fixed_effects
means_df = as.data.frame(cbind(means,groups[,2:3]))

means_df$odds = exp(means_df$means)
means_df$prob = means_df$odds/(1+means_df$odds)

@
@


\subsection {Raw Data: Subject}

<<>>=
#  since finaldata has several missing trials -- need 704 have 662, ANOVA is probably not the best idea -- thus, we run a linear model
PrimeRetrieval_fig = PrimeRetrieval
PrimeRetrieval_fig$primefac = ordered(as.factor(as.character(PrimeRetrieval_fig$PrimeCondition)), levels = c("B", "R", "P", "U"))

PrimeRetrieval_fig$PrimeFirstResp_ACC_fac = ordered(as.factor(as.character(PrimeRetrieval_fig$PrimeFirstResp_ACC)), levels = c("Retrieved", "Not Retrieved"))

agg_sub_ya = group_by(PrimeRetrieval_fig, Subject, primefac,
                       PrimeFirstResp_ACC_fac) %>%
  summarise_at(vars(Accuracy), mean)

agg_prime_ya= Rmisc::summarySE(agg_sub_ya, 
                      measurevar = "Accuracy",
                      groupvars = c("PrimeFirstResp_ACC_fac", "primefac"))

agg_prime_ya$PrimeFirstResp_ACC = as.factor(agg_prime_ya$PrimeFirstResp_ACC)
library(ggplot2)
library(ggthemes)


x = agg_prime_ya %>% mutate(PrimeType = factor(primefac, 
                                        levels = unique(primefac),
                    labels = c("Both","Semantic", "Phonological",
                                "Unrelated")),
                    `Prime Retrieval` = factor(PrimeFirstResp_ACC_fac, 
                                levels = unique(PrimeFirstResp_ACC_fac),
                    labels = c("Retrieved", "Not Retrieved")))%>%
  ggplot(aes(x = `Prime Retrieval`, y = Accuracy, 
                          group =PrimeType , 
                          fill = PrimeType)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.5,
           color ="gray28")+
   geom_errorbar(aes(ymin = Accuracy - se, 
                     ymax = Accuracy + se),
                width=.08, position=position_dodge(.5)) +
  theme_few()+
#  scale_fill_canva()+
 scale_fill_manual(values = c( "lightsalmon", "red",
                               "paleturquoise3","lightgreen"))+       
  xlab("Prime Retrieval") + ylab("Mean Target Accuracy") + 
  ylim (0,0.55)+
ggtitle(" Experiment 3") +
  theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5, size = rel(1)),
         axis.text.x = element_text(face = "bold", size = rel(1.2)))

library(grid)
gridExtra::grid.arrange(x,  top=textGrob("Target Retrieval Accuracy as a function of \nPrime Retrieval and Prime Condition in Experiments 3, 4 and 5",
                                      gp=gpar(fontsize=16)))
@


\subsection {Raw Data: Item}

<<>>=
#  since finaldata has several missing trials -- need 704 have 662, ANOVA is probably not the best idea -- thus, we run a linear model
agg_item_ya = group_by(PrimeRetrieval_fig, Stimuli2, primefac,
                       PrimeFirstResp_ACC_fac) %>%
  summarise_at(vars(Accuracy), mean)

agg_prime_ya_item= Rmisc::summarySE(agg_item_ya, 
                      measurevar = "Accuracy",
                      groupvars = c("PrimeFirstResp_ACC_fac", "primefac"))

agg_prime_ya_item$PrimeFirstResp_ACC = as.factor(agg_prime_ya_item$PrimeFirstResp_ACC)
library(ggplot2)
library(ggthemes)


agg_prime_ya_item %>% mutate(PrimeType = factor(primefac, 
                                        levels = unique(primefac),
                    labels = c("Both","Semantic", "Phonological",
                                "Unrelated")),
                    `Prime Retrieval` = factor(PrimeFirstResp_ACC_fac, 
                                levels = unique(PrimeFirstResp_ACC_fac),
                    labels = c("Retrieved", "Not Retrieved")))%>%
  ggplot(aes(x = `Prime Retrieval`, y = Accuracy, 
                          group =PrimeType , 
                          fill = PrimeType)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.5,
           color ="gray28")+
   geom_errorbar(aes(ymin = Accuracy - se, 
                     ymax = Accuracy + se),
                width=.08, position=position_dodge(.5)) +
  theme_few()+
#  scale_fill_canva()+
 scale_fill_manual(values = c( "lightsalmon", "red",
                               "paleturquoise3","lightgreen"))+       
  xlab("Prime Retrieval") + ylab("Mean Target Accuracy") + 
  ylim (0,0.55)+
ggtitle(" Experiment 3") +
  theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5, size = rel(1)),
         axis.text.x = element_text(face = "bold", size = rel(1.2)))

@
\subsection {Meaning Not Meaning}

<<>>=
## Collapse R and B, and P and U
PrimeRetrieval_fig$Relationship = ifelse(PrimeRetrieval_fig$PrimeCondition %in% 
                                       c("B", "R"), "Meaning", "NotMeaning")
PrimeRetrieval_fig$Relationship = as.factor(PrimeRetrieval_fig$Relationship)

@

\subsubsection {Subject}
<<>>=

## SUBJECT
e3_ret_notret_agg = group_by(PrimeRetrieval_fig, Subject, Relationship,
                             PrimeFirstResp_ACC) %>%
  summarise_at(vars(Accuracy), mean)
e3_ret_notret_agg$Subject = as.factor(e3_ret_notret_agg$Subject)
e3_ret_notret_agg_aov = aov(data = e3_ret_notret_agg, 
                            Accuracy ~ PrimeFirstResp_ACC*Relationship +
                       Error(Subject/PrimeFirstResp_ACC*Relationship))

summary(e3_ret_notret_agg_aov)

meaning = e3_ret_notret_agg %>% filter(Relationship == "Meaning")
notmeaning = e3_ret_notret_agg %>% filter(Relationship == "NotMeaning")
meaning_ret = meaning %>% filter(PrimeFirstResp_ACC == "Retrieved")
meaning_notret = meaning %>% filter(PrimeFirstResp_ACC == "Not Retrieved")

notmeaning_ret = notmeaning %>% filter(PrimeFirstResp_ACC == "Retrieved")
notmeaning_notret = notmeaning %>% filter(PrimeFirstResp_ACC == "Not Retrieved")

t.test(meaning_ret$Accuracy, notmeaning_ret$Accuracy, paired = TRUE)
t.test(meaning_notret$Accuracy, notmeaning_notret$Accuracy, paired = TRUE)

agg_prime_ya= Rmisc::summarySE(e3_ret_notret_agg, 
                      measurevar = "Accuracy",
                groupvars = c("PrimeFirstResp_ACC", "Relationship"))

library(ggplot2)
library(ggthemes)


agg_prime_ya %>% mutate( `Prime Retrieval` = factor(PrimeFirstResp_ACC, 
                                levels = unique(PrimeFirstResp_ACC),
                    labels = c("Not Retrieved", "Retrieved")))%>%
  ggplot(aes(x = `Prime Retrieval`, y = Accuracy, 
                          group =Relationship , 
                          fill = Relationship)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.5,
           color ="gray28")+
   geom_errorbar(aes(ymin = Accuracy - se, 
                     ymax = Accuracy + se),
                width=.08, position=position_dodge(.5)) +
  theme_few()+
 scale_fill_colorblind()+
  xlab("Prime Retrieval") + ylab("Mean Target Accuracy") + 
  ylim (0,0.55)+
ggtitle(" Experiment 3") +
  theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5, size = rel(1)),
         axis.text.x = element_text(face = "bold", size = rel(1.2)))

@

\subsubsection {Item}
<<>>=
## ITEM
e3_ret_notret_agg_item = group_by(PrimeRetrieval_fig, 
                                  Stimuli2, Relationship,
                             PrimeFirstResp_ACC) %>%
  summarise_at(vars(Accuracy), mean)

e3_ret_notret_agg_item = e3_ret_notret_agg_item %>%
  filter(! Stimuli2 %in% c(9,26,57))

e3_ret_notret_agg_item$Stimuli2 = as.factor(e3_ret_notret_agg_item$Stimuli2)
e3_ret_notret_agg_aov_item = aov(data = e3_ret_notret_agg_item, 
                            Accuracy ~ PrimeFirstResp_ACC*Relationship +
                       Error(Stimuli2/PrimeFirstResp_ACC*Relationship))

summary(e3_ret_notret_agg_aov_item)

meaning = e3_ret_notret_agg_item %>% filter(Relationship == "Meaning")
notmeaning = e3_ret_notret_agg_item %>% filter(Relationship == "NotMeaning")
meaning_ret = meaning %>% filter(PrimeFirstResp_ACC == "Retrieved")
meaning_notret = meaning %>% filter(PrimeFirstResp_ACC == "Not Retrieved")

notmeaning_ret = notmeaning %>% filter(PrimeFirstResp_ACC == "Retrieved")
notmeaning_notret = notmeaning %>% filter(PrimeFirstResp_ACC == "Not Retrieved")

t.test(meaning_ret$Accuracy, notmeaning_ret$Accuracy, paired = TRUE)
t.test(meaning_notret$Accuracy, notmeaning_notret$Accuracy, paired = TRUE)

agg_prime_ya= Rmisc::summarySE(e3_ret_notret_agg_item, 
                      measurevar = "Accuracy",
                groupvars = c("PrimeFirstResp_ACC", "Relationship"))

library(ggplot2)
library(ggthemes)


agg_prime_ya %>% mutate( `Prime Retrieval` = factor(PrimeFirstResp_ACC, 
                                levels = unique(PrimeFirstResp_ACC),
                    labels = c("Not Retrieved", "Retrieved")))%>%
  ggplot(aes(x = `Prime Retrieval`, y = Accuracy, 
                          group =Relationship , 
                          fill = Relationship)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.5,
           color ="gray28")+
   geom_errorbar(aes(ymin = Accuracy - se, 
                     ymax = Accuracy + se),
                width=.08, position=position_dodge(.5)) +
  theme_few()+
 scale_fill_colorblind()+
  xlab("Prime Retrieval") + ylab("Mean Target Accuracy") + 
  ylim (0,0.55)+
ggtitle(" Experiment 3") +
  theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5, size = rel(1)),
         axis.text.x = element_text(face = "bold", size = rel(1.2)))

@

\section {Easy vs Difficult Items}

\subsection {Subject Level}

<<>>=
mean_item_acc = group_by(PrimeRetrieval_fig, Stimuli2) %>%
  summarise_at(vars(Accuracy), mean)

medianItemAcc = median(mean_item_acc$Accuracy)

e3_ret_notret_agg$ItemDifficulty = ifelse(e3_ret_notret_agg$Accuracy < medianItemAcc, "Difficult", "Easy")

e3_ret_notret_agg$ItemDifficulty = as.factor(e3_ret_notret_agg$ItemDifficulty)

agg_prime_ya_diff= Rmisc::summarySE(e3_ret_notret_agg, 
                      measurevar = "Accuracy",
                groupvars = c("PrimeFirstResp_ACC", "Relationship",
                              "ItemDifficulty"))

library(ggplot2)
library(ggthemes)


agg_prime_ya_diff %>% mutate( `Prime Retrieval` = factor(PrimeFirstResp_ACC, 
                                levels = unique(PrimeFirstResp_ACC),
                    labels = c("Not Retrieved", "Retrieved")))%>%
  ggplot(aes(x = `Prime Retrieval`, y = Accuracy, 
                          group =Relationship , 
                          fill = Relationship)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.5,
           color ="gray28")+
   geom_errorbar(aes(ymin = Accuracy - se, 
                     ymax = Accuracy + se),
                width=.08, position=position_dodge(.5)) +
  facet_wrap(~ItemDifficulty)+
  theme_few()+
 scale_fill_colorblind()+
  xlab("Prime Retrieval") + ylab("Mean Target Accuracy") + 
  ylim (0,0.55)+
ggtitle(" Experiment 3") +
  theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5, size = rel(1)),
         axis.text.x = element_text(face = "bold", size = rel(1.2)))

@

\subsection {Item Level}

<<>>=
mean_item_acc = group_by(PrimeRetrieval_fig, Stimuli2) %>%
  summarise_at(vars(Accuracy), mean)

medianItemAcc = median(mean_item_acc$Accuracy)

e3_ret_notret_agg_item$ItemDifficulty = ifelse(e3_ret_notret_agg_item$TargetFirstResp_ACC < medianItemAcc, "Difficult", "Easy")

e3_ret_notret_agg_item$ItemDifficulty = as.factor(e3_ret_notret_agg_item$ItemDifficulty)

agg_prime_ya_diff_item= Rmisc::summarySE(e3_ret_notret_agg_item, 
                      measurevar = "Accuracy",
                groupvars = c("PrimeFirstResp_ACC", "Relationship",
                              "ItemDifficulty"))

library(ggplot2)
library(ggthemes)


agg_prime_ya_diff_item %>% mutate( `Prime Retrieval` = factor(PrimeFirstResp_ACC, 
                                levels = unique(PrimeFirstResp_ACC),
                    labels = c("Not Retrieved", "Retrieved")))%>%
  ggplot(aes(x = `Prime Retrieval`, y = Accuracy, 
                          group =Relationship , 
                          fill = Relationship)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.5,
           color ="gray28")+
   geom_errorbar(aes(ymin = Accuracy - se, 
                     ymax = Accuracy + se),
                width=.08, position=position_dodge(.5)) +
  facet_wrap(~ItemDifficulty)+
  theme_few()+
 scale_fill_colorblind()+
  xlab("Prime Retrieval") + ylab("Mean Target Accuracy") + 
ggtitle(" Experiment 3") +
  theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5, size = rel(1)),
         axis.text.x = element_text(face = "bold", size = rel(1.2)))

@



\subsection {Raw Data Collapsed}

<<>>=
#  since finaldata has several missing trials -- need 704 have 662, ANOVA is probably not the best idea -- thus, we run a linear model

agg_prime_ya2= Rmisc::summarySE(PrimeRetrieval, 
                      measurevar = "Accuracy",
                      groupvars = c("PrimeCondition"))

agg_prime_ya$PrimeFirstResp_ACC = as.factor(agg_prime_ya$PrimeFirstResp_ACC)
library(ggplot2)
library(ggthemes)

agg_prime_ya2 %>% mutate(PrimeType = factor(PrimeCondition, 
                                        levels = unique(PrimeCondition),
                    labels = c("Both", "Phonological",
                               "Semantic", "Unrelated")))%>%
  ggplot(aes(x = PrimeType, y = Accuracy)) +  
  geom_bar(stat = "identity", position = "dodge", width = 0.5,
           color ="gray28")+
   geom_errorbar(aes(ymin = Accuracy - se, 
                     ymax = Accuracy + se),
                width=.08, position=position_dodge(.5)) +
  theme_few()+
  scale_fill_manual(values= c("slategray4", "slategray1"))+
       xlab("Prime Condition") + ylab("Mean Target Accuracy") + 
ggtitle("YA: Target Retrieval ~ \nPrime Retrieval x Prime Condition") +
  theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5),
         axis.text.x = element_text(face = "bold", size = rel(1.2)))
@

\subsection *{Figures: Mean Accuracy}

\subsubsection *{Target}
<<>>=
agg_acc = Rmisc::summarySE(agg_sub_condition, 
                      measurevar = "Accuracy",
                      groupvars = c("PrimeCondition"))

library(ggplot2)
library(ggthemes)
 agg_acc %>% mutate(PrimeType = factor(PrimeCondition, 
                                                 levels = unique(PrimeCondition),
                    labels = c("Both", "Phonological", 
                               "Semantic", "Unrelated")))%>%
  ggplot(aes(x = PrimeType, y = Accuracy)) + 
 geom_bar(stat = "identity", position = "dodge", width = 0.5, 
          fill = "royalblue4", color = "black")+
   geom_errorbar(aes(ymin = Accuracy - se, ymax = Accuracy + se),
                width=.05, position=position_dodge(.5)) +
    theme_few()+
   xlab("Prime Condition") + ylab("Mean Target Retrieval Accuracy") + 
  ggtitle("")  +
   theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5),
         strip.text.x = element_text(face = "bold", size = rel(1.4)))

@

\subsubsection *{Prime}
<<>>=


agg_prime_acc = Rmisc::summarySE(agg_sub_prime, 
                      measurevar = "PrimeFirstResp_ACC",
                      groupvars = c("PrimeCondition"))
agg_prime_acc$PrimeFirstResp_ACC = round(agg_prime_acc$PrimeFirstResp_ACC,
                                         digits = 2)
library(ggplot2)
library(ggthemes)
 agg_prime_acc %>% mutate(PrimeType = factor(PrimeCondition, 
                                        levels = unique(PrimeCondition),
                    labels = c("Both", "Phonological", 
                               "Semantic", "Unrelated")))%>%
  ggplot(aes(x = PrimeType, y = PrimeFirstResp_ACC)) + 
 geom_bar(stat = "identity", position = "dodge", width = 0.5, 
          fill = "royalblue4", color = "black")+
   geom_errorbar(aes(ymin = PrimeFirstResp_ACC - se, 
                     ymax = PrimeFirstResp_ACC + se),
                width=.05, position=position_dodge(.5)) +
    theme_few()+
   xlab("Prime Condition") + ylab("Mean Prime Retrieval Accuracy") + 
  ggtitle("")  +
   theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5),
         strip.text.x = element_text(face = "bold", size = rel(1.4)))

@
\subsection *{Prime Ret/Not}
\subsubsection *{Proportions by Target Accuracy}

<<>>=
agg_ret_target = Rmisc::summarySE(merged_agg_primeret_all, 
                      measurevar = "ProportionTarget",
                      groupvars = c("TargetAccuracy", "PrimeRetrieved"))

library(ggplot2)
library(ggthemes)
agg_ret_target %>% mutate(TargetAccuracy = factor(TargetAccuracy, 
                                                 levels = unique(TargetAccuracy),
                    labels = c("Incorrect Target", "Correct Target")))%>%
ggplot(aes(x = TargetAccuracy, y = ProportionTarget, 
                    group = PrimeRetrieved, fill = PrimeRetrieved)) + 
 geom_bar(stat = "identity", position = "dodge", width = 0.5)+
   geom_errorbar(aes(ymin = ProportionTarget - ci, ymax = ProportionTarget + ci),
                width=.05, position=position_dodge(.5)) +
     theme_few()+
  scale_fill_hc()+
      xlab("Target Accuracy") + ylab("Mean Proportion of Trials") + 
    ggtitle("Mean Proportion of \nCorrect/Incorrect Trials by Prime Retrieval") 
@

\subsubsection *{Proportions by Prime Accuracy}

<<>>=
agg_ret_prime = Rmisc::summarySE(merged_agg_primeret_all, 
                      measurevar = "ProportionPrime",
                      groupvars = c("TargetAccuracy", "PrimeRetrieved"))

library(ggplot2)
library(ggthemes)
agg_ret_prime %>% mutate(`Target Retrieval`= factor(TargetAccuracy, 
                                  levels = unique(TargetAccuracy),
                    labels = c("Failed Retrieval", "Successful Retrieval")),
                   `Prime Retrieval`= factor(PrimeRetrieved, 
                                  levels = unique(PrimeRetrieved),
               labels = c("Prime Not Retrieved", "Prime Retrieved")))%>% 
ggplot(aes(x = `Prime Retrieval`, y = ProportionPrime, 
                    group = `Target Retrieval`, fill = `Target Retrieval`)) + 
 geom_bar(stat = "identity", position = "dodge", width = 0.5)+
   geom_errorbar(aes(ymin = ProportionPrime - ci, ymax = ProportionPrime + ci),
                width=.05, position=position_dodge(.5)) +
     theme_few()+
  scale_fill_wsj()+
      xlab("Prime Retrieval") + ylab("Mean Proportion of Trials") + 
ggtitle("YA: Mean Proportion of Correct/Incorrect \nTrials by Prime Retrieval") +
  theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5),
         strip.text.x = element_text(face = "bold", size = rel(1.4)))
@

\section *{State Data}

<<>>=

state_prime_counts = group_by(PrimeRetrieval,Subject,
                              PrimeCondition, TargetQuestion) %>%
  summarise(Trials = n())
  

state_prime = Rmisc::summarySE(state_prime_counts, 
                      measurevar = "Trials",
                      groupvars = c("PrimeCondition", "TargetQuestion"))

library(ggplot2)
library(ggthemes)
state_prime %>% mutate(PrimeType = factor(PrimeCondition, 
                    levels = unique(PrimeCondition),
                    labels = c("Both", "Phonological", 
                               "Semantic", "Unrelated")),
  State1 = factor(TargetQuestion, levels = unique(TargetQuestion),
                          labels = c("Know", "Dont Know", 
                                     "Other", "TOT")))%>%
  ggplot(aes(x = PrimeType, y = Trials, fill = State1))+
 geom_bar(stat = "identity", position = "dodge", width = 0.5)+
  geom_errorbar(aes(ymin = Trials - ci, ymax = Trials + ci),
                width=.05, position=position_dodge(.5)) +
  scale_fill_colorblind()+
  theme_few()+
  xlab("Prime Condition") + ylab("Mean Number of Trials") + 
  ggtitle("YA: Target Retrieval States by Prime Condition")+
  theme(axis.text = element_text(face = "bold", size = rel(1.2)),
          axis.title = element_text(face = "bold", size = rel(1.2)),
          legend.title = element_text(face = "bold", size = rel(1.2)),
                   strip.text.x = element_text(face = "bold", size = rel(1.4)),
      plot.title = element_text(face = "bold", size = rel(1.2), hjust = .5))

@

\subsection {Percentage State Prime Analysis}

<<>>=
state = read.csv("YAOA_agg_FINAL.csv",header = TRUE, sep = ",")
state = state %>% filter(Age == "Young")

j_statepercent = state[,c(2,3,160:175)] # use for prime percents
j_statepercent$Subject = as.factor(j_statepercent$Subject)

library(tidyr)
library(dplyr)
statepercent <- j_statepercent %>%
  gather(PrimeState, Percent, 
         prop_r_know, prop_r_dontknow, prop_r_other, prop_r_TOT,
         prop_p_know, prop_p_dontknow, prop_p_other, prop_p_TOT,
         prop_b_know, prop_b_dontknow, prop_b_other, prop_b_TOT,
         prop_u_know, prop_u_dontknow, prop_u_other, prop_u_TOT) %>%
  separate(PrimeState, c('Prop', 'Prime', 'State'), sep = "_") %>%
  arrange(Subject)
#removing prop
statepercent = statepercent[,-3]

colnames(statepercent) = c( "Subject","AgeGroup",
                            "PrimeCondition", "State", "Percent")

statepercent$AgeGroup <- as.factor(statepercent$AgeGroup)
statepercent$Subject <- as.factor(statepercent$Subject)
statepercent$PrimeCondition <- as.factor(statepercent$PrimeCondition)
statepercent$State <- as.factor(statepercent$State)
statepercent$Percent <- as.numeric(as.character(statepercent$Percent))

## anova

state_aov = aov(data = statepercent, Percent ~ PrimeCondition*State + 
                  Error(Subject/(PrimeCondition*State)))
summary(state_aov)
@ 
\subsubsection {plot}
<<>>=
## figure
state_rmisc = Rmisc::summarySE(statepercent,
                               measurevar = "Percent",
                               groupvars = c("PrimeCondition","State"))

x <- c("know","dontknow", "other", "TOT")

state_rmisc = state_rmisc %>%
  mutate(rstate =  factor(State, levels = x)) %>%
  arrange(rstate)

library(ggplot2)
library(ggthemes)

percentplot = state_rmisc %>% 
  mutate(PrimeType = factor(PrimeCondition, levels = unique(PrimeCondition),
                    labels = c("Both", "Phonological", 
                               "Semantic", "Unrelated")),
   R = factor(rstate, levels = unique(rstate),
                                labels = c( "1: Know","2: Dont Know",
                                            "3:Other", "4: TOT")))%>%
  
ggplot(aes(x = R, y = Percent, 
           group = PrimeType, fill = PrimeType))+
 geom_bar(stat = "identity", position = "dodge", width = 0.7, 
          color= "black")+
  geom_errorbar(aes(ymin=Percent - se, ymax=Percent + se), 
             width=.2, color = "gray26", 
             position = position_dodge(0.7))+
 theme_few()+
    xlab("") + ylab("Percentage of trials") + 
 scale_fill_manual(values = c( "lightsalmon", "red",
                               "paleturquoise3","lightgreen"))+    
  ggtitle("E3: Young Adults")  +
   theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5),
                  axis.text.x = element_text(size = rel(1)),
         strip.text.x = element_text(face = "bold", size = rel(1.4)))
percentplot
@

\subsubsection {know}

<<>>=
e3_know = statepercent %>% filter(State == "know")
e3_know_aov = aov(data = e3_know, 
                          Percent ~ PrimeCondition + 
                        Error(Subject/PrimeCondition))
summary(e3_know_aov)
@
\subsubsection {dont know}

<<>>=
e3_dontknow = statepercent %>% filter(State == "dontknow")
e3_dontknow_aov = aov(data = e3_dontknow, 
                          Percent ~ PrimeCondition + 
                        Error(Subject/PrimeCondition))
summary(e3_dontknow_aov)
@

\subsubsection {other}
<<>>=

e3_other = statepercent %>% filter(State == "other")
e3_other_aov = aov(data = e3_other, 
                          Percent ~ PrimeCondition + 
                        Error(Subject/PrimeCondition))
summary(e3_other_aov)
@

\subsubsection{ TOT}
<<>>=

e3_TOT = statepercent %>% filter(State == "TOT")
e3_TOT_aov = aov(data = e3_TOT, 
                          Percent ~ PrimeCondition + 
                        Error(Subject/PrimeCondition))
summary(e3_TOT_aov)
@

\subsection {Split by Prime and Target Accuracy}

\subsubsection {anova}

<<>>=
state_acc = state[,c(2,3,96:159)] 
state_acc$Subject = as.factor(state_acc$Subject)

library(tidyr)
library(dplyr)
stateaccnums <- state_acc %>%
  gather(PrimeStatePrimeRetTarget, Trials, 
         r_know_p1_t1, r_know_p1_t0, r_know_p0_t1, r_know_p0_t0,
         p_know_p1_t1, p_know_p1_t0, p_know_p0_t1, p_know_p0_t0,
         b_know_p1_t1, b_know_p1_t0, b_know_p0_t1, b_know_p0_t0,
         u_know_p1_t1, u_know_p1_t0, u_know_p0_t1, u_know_p0_t0,
   r_dontknow_p1_t1,r_dontknow_p1_t0, r_dontknow_p0_t1,r_dontknow_p0_t0,
   p_dontknow_p1_t1,p_dontknow_p1_t0, p_dontknow_p0_t1,p_dontknow_p0_t0,
   b_dontknow_p1_t1,b_dontknow_p1_t0, b_dontknow_p0_t1,b_dontknow_p0_t0,
   u_dontknow_p1_t1,u_dontknow_p1_t0, u_dontknow_p0_t1,u_dontknow_p0_t0,
    r_other_p1_t1, r_other_p1_t0,r_other_p0_t1, r_other_p0_t0,
    p_other_p1_t1, p_other_p1_t0,p_other_p0_t1, p_other_p0_t0,
    b_other_p1_t1, b_other_p1_t0,b_other_p0_t1, b_other_p0_t0,
    u_other_p1_t1, u_other_p1_t0,u_other_p0_t1, u_other_p0_t0,
    r_TOT_p1_t1, r_TOT_p1_t0, r_TOT_p0_t1, r_TOT_p0_t0,
    p_TOT_p1_t1, p_TOT_p1_t0, p_TOT_p0_t1, p_TOT_p0_t0,
    b_TOT_p1_t1, b_TOT_p1_t0, b_TOT_p0_t1, b_TOT_p0_t0,
    u_TOT_p1_t1, u_TOT_p1_t0, u_TOT_p0_t1, u_TOT_p0_t0) %>%
  separate(PrimeStatePrimeRetTarget, c( 'Prime', 'State', 
                          'PrimeRet', 'TargetAcc'), sep = "_") %>%
  arrange(Subject)

stateaccnums$Subject <- as.factor(stateaccnums$Subject)
stateaccnums$Prime <- as.factor(stateaccnums$Prime)
stateaccnums$State <- as.factor(stateaccnums$State)
stateaccnums$PrimeRet <- as.factor(stateaccnums$PrimeRet)
stateaccnums$TargetAcc <- as.factor(stateaccnums$TargetAcc)
stateaccnums$Trials <- as.numeric(as.character(stateaccnums$Trials))


mainstate_aov = aov(data = stateaccnums, 
                    Trials ~ Prime*State*PrimeRet*TargetAcc +
                      Error(Subject/(Prime*State*PrimeRet*TargetAcc)))
summary(mainstate_aov)

@

\subsubsection {plot}

<<>>=
## figure
stateacc_rmisc = Rmisc::summarySE(stateaccnums,
                               measurevar = "Trials",
                               groupvars = c("Prime","State",
                                             "PrimeRet", "TargetAcc"))

x <- c("know","dontknow", "other", "TOT")

stateacc_rmisc = stateacc_rmisc %>%
  mutate(rstate =  factor(State, levels = x)) %>%
  arrange(rstate)

know_rmisc = stateacc_rmisc %>% filter(State == "know")
dontknow_rmisc = stateacc_rmisc %>% filter(State == "dontknow")
other_rmisc = stateacc_rmisc %>% filter(State == "other")
TOT_rmisc = stateacc_rmisc %>% filter(State == "TOT")

library(ggplot2)
library(ggthemes)

know_percentplot = know_rmisc %>% 
  mutate(PrimeType = factor(Prime, levels = unique(Prime),
                    labels = c("Both", "Phonological", 
                               "Semantic", "Unrelated")))%>%
ggplot(aes(x = PrimeType, y = Trials,
             fill = TargetAcc, group=TargetAcc)) + 
 geom_bar(stat = "identity", position = "dodge", width = 0.7, 
          color= "black")+
  geom_errorbar(aes(ymin=Trials - se, ymax=Trials + se), 
             width=.2, color = "gray26", 
             position = position_dodge(0.7))+
 theme_few()+
  facet_wrap(~PrimeRet)+
    xlab("") + ylab("") + 
  ggtitle("YA Know Responses")  +
   theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5),
                  axis.text.x = element_text(size = rel(1)),
         strip.text.x = element_text(face = "bold", size = rel(1.4)))
know_percentplot

dontknow_percentplot = dontknow_rmisc %>% 
  mutate(PrimeType = factor(Prime, levels = unique(Prime),
                    labels = c("Both", "Phonological", 
                               "Semantic", "Unrelated")))%>%
ggplot(aes(x = PrimeType, y = Trials,
             fill = TargetAcc, group=TargetAcc)) + 
 geom_bar(stat = "identity", position = "dodge", width = 0.7, 
          color= "black")+
  geom_errorbar(aes(ymin=Trials - se, ymax=Trials + se), 
             width=.2, color = "gray26", 
             position = position_dodge(0.7))+
 theme_few()+
  facet_wrap(~PrimeRet)+
    xlab("") + ylab("") + 
  ggtitle("YA Dont Know Responses")  +
   theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5),
                  axis.text.x = element_text(size = rel(1)),
         strip.text.x = element_text(face = "bold", size = rel(1.4)))
dontknow_percentplot

other_percentplot = other_rmisc %>% 
  mutate(PrimeType = factor(Prime, levels = unique(Prime),
                    labels = c("Both", "Phonological", 
                               "Semantic", "Unrelated")))%>%
ggplot(aes(x = PrimeType, y = Trials,
             fill = TargetAcc, group=TargetAcc)) + 
 geom_bar(stat = "identity", position = "dodge", width = 0.7, 
          color= "black")+
  geom_errorbar(aes(ymin=Trials - se, ymax=Trials + se), 
             width=.2, color = "gray26", 
             position = position_dodge(0.7))+
 theme_few()+
  facet_wrap(~PrimeRet)+
    xlab("") + ylab("") + 
  ggtitle("YA Other Responses")  +
   theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5),
                  axis.text.x = element_text(size = rel(1)),
         strip.text.x = element_text(face = "bold", size = rel(1.4)))
other_percentplot

TOT_percentplot = TOT_rmisc %>% 
  mutate(PrimeType = factor(Prime, levels = unique(Prime),
                    labels = c("Both", "Phonological", 
                               "Semantic", "Unrelated")))%>%
ggplot(aes(x = PrimeType, y = Trials,
             fill = TargetAcc, group=TargetAcc)) + 
 geom_bar(stat = "identity", position = "dodge", width = 0.7, 
          color= "black")+
  geom_errorbar(aes(ymin=Trials - se, ymax=Trials + se), 
             width=.2, color = "gray26", 
             position = position_dodge(0.7))+
 theme_few()+
  facet_wrap(~PrimeRet)+
    xlab("") + ylab("") + 
  ggtitle("YA TOT Responses")  +
   theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5),
                  axis.text.x = element_text(size = rel(1)),
         strip.text.x = element_text(face = "bold", size = rel(1.4)))
TOT_percentplot
@

\subsection {Split by Target Accuracy in each state}

\subsubsection {anova}

<<>>=
state_targetacc = state[,c(2,3,192:223)] 
state_targetacc$Subject = as.factor(state_targetacc$Subject)

library(tidyr)
library(dplyr)
stateaccnums_target <- state_targetacc %>%
  gather(PrimeStatePrimeRetTarget, Trials, 
         r_know_t1, r_know_t0, 
         p_know_t1, p_know_t0, 
         b_know_t1, b_know_t0, 
         u_know_t1, u_know_t0, 
   r_dontknow_t1,r_dontknow_t0, 
   p_dontknow_t1,p_dontknow_t0, 
   b_dontknow_t1,b_dontknow_t0, 
   u_dontknow_t1,u_dontknow_t0, 
    r_other_t1, r_other_t0,
    p_other_t1, p_other_t0,
    b_other_t1, b_other_t0,
    u_other_t1, u_other_t0,
    r_TOT_t1, r_TOT_t0,
    p_TOT_t1, p_TOT_t0, 
    b_TOT_t1, b_TOT_t0,
    u_TOT_t1, u_TOT_t0) %>%
  separate(PrimeStatePrimeRetTarget, c( 'Prime', 'State', 
                           'TargetAcc'), sep = "_") %>%
  arrange(Subject)

stateaccnums_target$Subject <- as.factor(stateaccnums_target$Subject)
stateaccnums_target$Prime <- as.factor(stateaccnums_target$Prime)
stateaccnums_target$State <- as.factor(stateaccnums_target$State)
stateaccnums_target$TargetAcc <- as.factor(stateaccnums_target$TargetAcc)
stateaccnums_target$Trials <- as.numeric(as.character(stateaccnums_target$Trials))


statetargetacc_aov = aov(data = stateaccnums_target, 
                    Trials ~ Prime*State*TargetAcc +
                      Error(Subject/(Prime*State*TargetAcc)))
summary(statetargetacc_aov)

@

\subsubsection {plot}
<<>>=
## figure
statetargetacc_rmisc = Rmisc::summarySE(stateaccnums_target,
                               measurevar = "Trials",
                               groupvars = c("Prime","State", "TargetAcc"))

x <- c("know","dontknow", "other", "TOT")

statetargetacc_rmisc = statetargetacc_rmisc %>%
  mutate(rstate =  factor(State, levels = x)) %>%
  arrange(rstate)

library(ggplot2)
library(ggthemes)

statetargetacc_plot = statetargetacc_rmisc %>% 
  mutate(PrimeType = factor(Prime, levels = unique(Prime),
                    labels = c("Both", "Phonological", 
                               "Semantic", "Unrelated")),
         TargetAccuracy = factor(TargetAcc, levels = unique(TargetAcc),
                    labels = c("Failed", "Correct")),
   R = factor(rstate, levels = unique(rstate),
                                labels = c( "1: Know","2: Dont Know",
                                            "3:Other", "4: TOT")))%>%
  
ggplot(aes(x = PrimeType, y = Trials, 
           group = TargetAccuracy, fill = TargetAccuracy))+
 geom_bar(stat = "identity", position = "dodge", width = 0.7, 
          color= "black")+
  geom_errorbar(aes(ymin=Trials - se, ymax=Trials + se), 
             width=.2, color = "gray26", 
             position = position_dodge(0.7))+
 theme_few()+
  facet_wrap(~R)+
    xlab("") + ylab("") + 
  ggtitle("YA States")  +
  scale_fill_wsj()+
   theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5),
                  axis.text.x = element_text(size = rel(1)),
         strip.text.x = element_text(face = "bold", size = rel(1.4)))
statetargetacc_plot
@


\section {Prime Demasking Analysis}

<<>>=
library(dplyr)

colnames(PrimeRetrieval) = c("Subject","AgeGroup", "ID",
                             "Procedure", 
                            "Prime", "Stimuli2","PrimeCondition", "Trial",
                             "PrimeDefResp", "PrimeFirstResp_ACC", 
                            "PrimeDefRT",  "PrimeRespRESP", "PrimeRespRT",
                             "Target", "TargetDefResp", "Accuracy",
                            "TargetDefRT",
                            "TargetRespRESP", "TargetRespRT",
                            "State", "StateRT",
                           "RTrecognisePrime", "RTrecogniseTarget",
                           "Count", "PrimeAcc", "MeanAcc")
#PrimeRetrieval = PrimeRetrieval %>% filter(PrimeAcc == 1)
primewith_firsttrim_target = subset(PrimeRetrieval, 
                                 PrimeRetrieval$RTrecogniseTarget > 250 &
                                PrimeRetrieval$RTrecogniseTarget < 7000)

primewith_firsttrim_prime = subset(PrimeRetrieval, 
                                 PrimeRetrieval$RTrecognisePrime > 250 &
                                PrimeRetrieval$RTrecognisePrime < 7000)

primewith_firsttrim_targetdef = subset(PrimeRetrieval, 
                                 PrimeRetrieval$TargetDefRT > 250 &
                                PrimeRetrieval$TargetDefRT < 9000)
@

\subsection*{RTRecogniseprime}

<<>>=
## FOR PRIME
## aggregate per subject all IVs and DVs
meanRT = group_by(primewith_firsttrim_prime, Subject) %>%
  summarise_at(vars(RTrecognisePrime), mean)
colnames(meanRT) = c("Subject", 
                     "MeanRTrecogPrime")

sdRT = group_by(primewith_firsttrim_prime, Subject) %>%
  summarise_at(vars(RTrecognisePrime), sd)
colnames(sdRT) = c("Subject",
                     "sdRTrecogPrime")

RT_agg = merge(meanRT, sdRT, by = "Subject")

## merge aggregate info with long data
primewith_z_prime = merge(primewith_firsttrim_prime, 
                             RT_agg, by = "Subject", all.x = T)

## person and grand-mean centered scores using original and aggregate
library(dplyr)
primewith_z_prime = primewith_z_prime %>% mutate(zPrimeRecogRT = 
                                             (RTrecognisePrime - 
                                                MeanRTrecogPrime)/sdRTrecogPrime)
                 
## checking: subject level means should be zero

sub_pic = group_by(primewith_z_prime, Subject) %>%
  summarise_at(vars(zPrimeRecogRT), mean)
@

\subsection*{RTRecogniseTarget}
<<>>=
## FOR TARGET
## aggregate per subject all IVs and DVs
meanRT = group_by(primewith_firsttrim_target, Subject) %>%
  summarise_at(vars(RTrecogniseTarget), mean)
colnames(meanRT) = c("Subject", "MeanRTrecogTarget")

sdRT = group_by(primewith_firsttrim_target, Subject) %>%
  summarise_at(vars(RTrecogniseTarget), sd)
colnames(sdRT) = c("Subject", "sdRTrecogTarget")

RT_agg = merge(meanRT, sdRT, by = "Subject")

## merge aggregate info with long data
primewith_z_target= merge(primewith_firsttrim_target,
                             RT_agg, by = "Subject", all.x = T)

## person and grand-mean centered scores using original and aggregate
library(dplyr)
primewith_z_target = primewith_z_target %>% mutate( zTargetRecogRT = 
                                             (RTrecogniseTarget - 
                                                MeanRTrecogTarget)/sdRTrecogTarget)
                 
## checking: subject level means should be zero

sub_pic = group_by(primewith_z_target, Subject) %>%
  summarise_at(vars(zTargetRecogRT), mean)

@

\subsection*{TargetDefRT}
<<>>=
## FOR TARGET
## aggregate per subject all IVs and DVs
meanRT = group_by(primewith_firsttrim_targetdef, Subject) %>%
  summarise_at(vars(TargetDefRT), mean)
colnames(meanRT) = c("Subject", "MeanTargetRT")

sdRT = group_by(primewith_firsttrim_targetdef, Subject) %>%
  summarise_at(vars(TargetDefRT), sd)
colnames(sdRT) = c("Subject", "sdTargetRT")

RT_agg = merge(meanRT, sdRT, by = "Subject")

## merge aggregate info with long data
primewith_z_targetdef = merge(primewith_firsttrim_targetdef,
                             RT_agg, by = "Subject", all.x = T)

## person and grand-mean centered scores using original and aggregate
library(dplyr)
primewith_z_targetdef = primewith_z_targetdef %>% mutate( zTargetRT = 
                                             (TargetDefRT - 
                                                MeanTargetRT)/sdTargetRT)
                 
## checking: subject level means should be zero

sub_pic = group_by(primewith_z_targetdef, Subject) %>%
  summarise_at(vars(zTargetRT), mean)

@

\section {Trimming z-RTs}

<<>>=

#Note: We are trimming based on PrimeRecog RT because that's the RT we care about most
primewith_z_trimmed_prime = subset(primewith_z_prime, 
                                primewith_z_prime$zPrimeRecogRT < 3 & 
                                  primewith_z_prime$zPrimeRecogRT > -3)

primewith_z_trimmed_target = subset(primewith_z_target, 
                                primewith_z_target$zTargetRecogRT < 3 & 
                                  primewith_z_target$zTargetRecogRT > -3)

primewith_z_trimmed_targetdef = subset(primewith_z_targetdef, 
                                primewith_z_targetdef$zTargetRT < 3 & 
                                  primewith_z_targetdef$zTargetRT > -3)
@

\section {Repeating z-scoring}

\subsection{For prime}

<<>>=
## aggregate per subject all IVs and DVs
meanRT_prime = group_by(primewith_z_trimmed_prime, Subject) %>%
  summarise_at(vars(RTrecognisePrime), mean)
colnames(meanRT_prime) = c("Subject", 
                     "MeanRTrecogPrime_trim")

sdRT_prime = group_by(primewith_z_trimmed_prime, Subject) %>%
  summarise_at(vars(RTrecognisePrime), sd)
colnames(sdRT_prime) = c("Subject",
                     "sdRTrecogPrime_trim")

RT_agg_prime = merge(meanRT_prime, sdRT_prime, by = "Subject")

## merge aggregate info with long data
primewith_final_z_prime = merge(primewith_z_trimmed_prime, 
                             RT_agg_prime, by = "Subject", all.x = T)

## person and grand-mean centered scores using original and aggregate
library(dplyr)
primewith_final_z_prime = primewith_final_z_prime %>% 
                                  mutate( zPrimeRecogRT_trim = 
                                             (RTrecognisePrime - 
                                      MeanRTrecogPrime_trim)/sdRTrecogPrime_trim)
                 
## checking: subject level means should be zero

sub_pic = group_by(primewith_final_z_prime, Subject) %>%
  summarise_at(vars(zPrimeRecogRT_trim), mean)

@

\subsection{For Target}

<<>>=
## aggregate per subject all IVs and DVs
meanRT_target = group_by(primewith_z_trimmed_target, Subject) %>%
  summarise_at(vars(RTrecogniseTarget), mean)
colnames(meanRT_target) = c("Subject", 
                     "MeanRTrecogTarget_trim")

sdRT_target = group_by(primewith_z_trimmed_target, Subject) %>%
  summarise_at(vars(RTrecogniseTarget), sd)
colnames(sdRT_target) = c("Subject", 
                      "sdRTrecogTarget_trim")

RT_agg_target = merge(meanRT_target, sdRT_target, by = "Subject")

## merge aggregate info with long data
primewith_final_z_target = merge(primewith_z_trimmed_target, 
                             RT_agg_target, by = "Subject", all.x = T)

## person and grand-mean centered scores using original and aggregate
library(dplyr)
primewith_final_z_target = primewith_final_z_target %>% 
                                  mutate( zTargetRecogRT_trim = 
                                             (RTrecogniseTarget - 
                                      MeanRTrecogTarget_trim)/sdRTrecogTarget_trim)
                 
## checking: subject level means should be zero

sub_pic = group_by(primewith_final_z_target, Subject) %>%
  summarise_at(vars(zTargetRecogRT_trim), mean)

@

\subsection{For TargetDefRT}

<<>>=
## aggregate per subject all IVs and DVs
meanRT_targetdef = group_by(primewith_z_trimmed_targetdef, Subject) %>%
  summarise_at(vars(TargetDefRT), mean)
colnames(meanRT_targetdef) = c("Subject", "MeanTargetRT_trim")

sdRT_targetdef = group_by(primewith_z_trimmed_targetdef, Subject) %>%
  summarise_at(vars(TargetDefRT), sd)
colnames(sdRT_targetdef) = c("Subject", "sdTargetRT_trim")

RT_agg_targetdef = merge(meanRT_targetdef, sdRT_targetdef, by = "Subject")

## merge aggregate info with long data
primewith_final_z_targetdef = merge(primewith_z_trimmed_targetdef, 
                             RT_agg_targetdef, by = "Subject", all.x = T)

## person and grand-mean centered scores using original and aggregate
library(dplyr)
primewith_final_z_targetdef = primewith_final_z_targetdef %>% 
                                  mutate(zTargetRT_trim = 
                                             (TargetDefRT - 
                                                MeanTargetRT_trim)/sdTargetRT_trim)
                 
## checking: subject level means should be zero

sub_pic = group_by(primewith_final_z_targetdef, Subject) %>%
  summarise_at(vars(zTargetRT_trim), mean)

@

\subsection {Combining z-RT Prime and Target }

<<>>=
## now we have separately z-scored RTprime and RTtarget. Need to combine.
## taking only necessary columns
primewith_final_z_prime2 = primewith_final_z_prime[,c(1,8,32)]

primewith_final_z = merge(primewith_final_z_target, 
                             primewith_final_z_prime2, 
                             by  = c("Subject", "Trial"))

primefinal_z_targetdef = merge(primewith_final_z_targetdef, 
                             primewith_final_z_prime2, 
                             by  = c("Subject", "Trial"))
@
\section {Linear Models}

<<>>=
# Mean RT to retrieve Target as a function of Prime Condition

# Effect of RT prime on Accuracy
library(lme4)
RTprime_acc_model = glmer(data = primewith_final_z, 
                          Accuracy ~ zPrimeRecogRT_trim + 
                            (1|Subject) + (1|Stimuli2), family = binomial )
summary(RTprime_acc_model)

library(sjPlot)
sjp.glmer(RTprime_acc_model, type = "pred", vars = "zPrimeRecogRT_trim")

contrasts(primewith_final_z_prime$PrimeCondition) = contr.treatment(n = 4, base = 4)

### NOTE: for Acc analysis, use the full primewith_final_z_prime data, why exclude 
## the RTrecogniseTarget when not using: greater power with this!
RTprime_acc_model_2 = glmer(data = primewith_final_z_prime, 
                          Accuracy ~ zPrimeRecogRT_trim*PrimeCondition + 
                            (1|Subject) + (1|Stimuli2), family = binomial )
summary(RTprime_acc_model_2)

options(contrasts = c("contr.sum","contr.poly"))
car::Anova(RTprime_acc_model_2)
anova(RTprime_acc_model_2)

RTprime_acc_model_2_2 = glmer(data = primewith_final_z_prime, 
                          Accuracy ~ zPrimeRecogRT_trim*PrimeCondition + 
                            (1|Subject),
                          family = binomial ,
                          control=glmerControl(optimizer="bobyqa",
            optCtrl=list(maxfun=100000)))

summary(RTprime_acc_model_2_2)
car::Anova(RTprime_acc_model_2_2)

anova(RTprime_acc_model_2_2, RTprime_acc_model_2)
@

<<>>=
y = sjPlot::plot_model(RTprime_acc_model_2, type = "int")
y + theme_few()+
      xlab("RT to Demask Prime") + ylab("Predicted Target Accuracy") + 
ggtitle("YA: Target Accuracy ~ \nDemasking RT x Prime Condition") +
  theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5),
         strip.text.x = element_text(face = "bold", size = rel(1.4)))


RTprime_acc_model_3 = glmer(data = primewith_final_z, 
            Accuracy ~ zPrimeRecogRT_trim*PrimeFirstResp_ACC*PrimeCondition + 
                            (1|Subject) + (1|Stimuli2), family = "binomial", 
    control=glmerControl(optimizer="bobyqa",
            optCtrl=list(maxfun=100000)))
summary(RTprime_acc_model_3)
car::Anova(RTprime_acc_model_3)

z = sjPlot::plot_model(RTprime_acc_model_3, type = "int", 
                   terms = c("zPrimeRecogRT_trim", "PrimeFirstResp_ACC"))

z + theme_few()+
      xlab("RT to Demask Prime") + ylab("Predicted Target Accuracy") + 
ggtitle("YA: Target Accuracy ~ \nDemasking RT x Prime Condition x Prime Retrieval Accuracy") +
  theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5),
         strip.text.x = element_text(face = "bold", size = rel(1.4)))
anova(RTprime_acc_model, RTprime_acc_model_2, RTprime_acc_model_3)

@

\subsection {Effect of Prime RT on Target RT}

<<>>=
library(lme4)
library(lmerTest)
contrasts(primewith_final_z$PrimeCondition) = contr.treatment(n = 4, base = 2)

RTprime_RT_model_2 = lmer(data = primewith_final_z, 
                    zTargetRecogRT_trim ~ zPrimeRecogRT_trim*PrimeCondition + 
                            (1|Subject) + (1|Stimuli2))
summary(RTprime_RT_model_2)
car::Anova(RTprime_RT_model_2)
options(contrasts = c("contr.sum","contr.poly"))
anova(RTprime_RT_model_2)

RTprime_RT_model_1 = lmer(data = primewith_final_z, 
                    zTargetRecogRT_trim ~ PrimeCondition + 
                            (1|Subject) + (1|Stimuli2))
summary(RTprime_RT_model_1)

anova(RTprime_RT_model_1, RTprime_RT_model_2)
car::Anova(RTprime_RT_model_1)

@

\subsection {Constrast Codes}

<<>>=
RT_fixedeff = matrix(fixef(RTprime_acc_model_2))

both = RT_fixedeff[1]
phon = RT_fixedeff[1] + RT_fixedeff[3]
sem =  RT_fixedeff[1] + RT_fixedeff[4]
unrel = RT_fixedeff[1] + RT_fixedeff[5]

final_means = as.data.frame(rbind(both, phon, sem, unrel))            
final_means$odds = exp(final_means$V1)
final_means$prob = final_means$odds/(1+final_means$odds)
                   
@

\subsection {Collapsing P and U conditions}

<<>>=
primewith_final_z$NewPrimes = ifelse(primewith_final_z$PrimeCondition == "P" | 
                    primewith_final_z$PrimeCondition == "U", "Unrelated", 
                    ifelse(primewith_final_z$PrimeCondition == "B", 
                           "Both", "Semantic" ))

RTprime_acc_model_2_new = glmer(data = primewith_final_z, 
                          Accuracy ~ zPrimeRecogRT_trim*NewPrimes + 
                            (1|Subject) + (1|Stimuli2), family = binomial )

summary(RTprime_acc_model_2_new)
car::Anova(RTprime_acc_model_2_new)
@

\subsection {Effect on Target Def RT}

<<>>=
library(lme4)
contrasts(primefinal_z_targetdef$PrimeCondition) = contr.treatment(4, base = 3)
RTprime_targetdefRT_model_1 = lmer(data = primefinal_z_targetdef, 
                    zTargetRT_trim ~ PrimeCondition + 
                            (1|Subject) + (1|Stimuli2))
summary(RTprime_targetdefRT_model_1)
car::Anova(RTprime_targetdefRT_model_1)


RTprime_targetdefRT_model_2 = lmer(data = primefinal_z_targetdef, 
                    zTargetRT_trim ~ PrimeFirstResp_ACC*PrimeCondition + 
                            (1|Subject) + (1|Stimuli2))
summary(RTprime_targetdefRT_model_2)
car::Anova(RTprime_targetdefRT_model_2)

RTprime_targetdefRT_model_3 = lmer(data = primefinal_z_targetdef, 
          zTargetRT_trim ~ PrimeFirstResp_ACC*zPrimeRecogRT_trim*PrimeCondition + 
                            (1|Subject) + (1|Stimuli2))
summary(RTprime_targetdefRT_model_3)
car::Anova(RTprime_targetdefRT_model_3)

anova(RTprime_targetdefRT_model_1, RTprime_targetdefRT_model_2)

RTprime_targetdefRT_model_4 = lmer(data = primefinal_z_targetdef, 
          zTargetRT_trim ~ PrimeFirstResp_ACC + 
                            (1|Subject) + (1|Stimuli2))
summary(RTprime_targetdefRT_model_4)
car::Anova(RTprime_targetdefRT_model_4)
anova(RTprime_targetdefRT_model_4, RTprime_targetdefRT_model_2)

RTprime_targetdefRT_model_5 = lmer(data = primefinal_z_targetdef, 
          zTargetRT_trim ~ zPrimeRecogRT_trim*PrimeCondition + 
                            (1|Subject) + (1|Stimuli2))
summary(RTprime_targetdefRT_model_5)
car::Anova(RTprime_targetdefRT_model_5)
anova(RTprime_targetdefRT_model_5, RTprime_targetdefRT_model_2)

@
\subsubsection {Model 1}

<<>>=
targetdefRT_rmisc = Rmisc::summarySE(primefinal_z_targetdef,
                                     measurevar = "zTargetRT_trim",
                                     groupvars = c("PrimeCondition"))

ggplot(targetdefRT_rmisc, aes(x = PrimeCondition, y = zTargetRT_trim,
                              fill = PrimeCondition))+
 geom_bar(stat = "identity", position = "dodge", width = 0.7, 
          color= "black")+
  geom_errorbar(aes(ymin=zTargetRT_trim - se, ymax=zTargetRT_trim + se), 
             width=.2, color = "gray26", 
             position = position_dodge(0.7))+
 theme_few()+
    xlab("Prime Condition") + ylab("z-RT") + 
  ggtitle("YA: Effect of Prime on RT to Retrieving Target")  +
  scale_fill_gdocs()+
   theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5),
                  axis.text.x = element_text(size = rel(1)),
         strip.text.x = element_text(face = "bold", size = rel(1.4)))
@
\subsubsection {Model 2}

<<>>=
targetdefRT_rmisc2 = Rmisc::summarySE(primefinal_z_targetdef,
                                     measurevar = "zTargetRT_trim",
                                     groupvars = c("PrimeFirstResp_ACC",
                                                   "PrimeCondition"))

ggplot(targetdefRT_rmisc2, aes(x = PrimeCondition, y = zTargetRT_trim,
                      group = PrimeFirstResp_ACC, fill = PrimeFirstResp_ACC))+
 geom_bar(stat = "identity", position = "dodge", width = 0.7, 
          color= "black")+
  geom_errorbar(aes(ymin=zTargetRT_trim - se, ymax=zTargetRT_trim + se), 
             width=.2, color = "gray26", 
             position = position_dodge(0.7))+
 theme_few()+
  xlab("Prime Condition") + ylab("z-RT") + 
  ggtitle("YA: Effect of Prime on Retrieving Target")  +
  scale_fill_wsj()+
   theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5),
                  axis.text.x = element_text(size = rel(1)),
         strip.text.x = element_text(face = "bold", size = rel(1.4)))
@

\subsubsection {Model 5}

<<>>=
primefinal_z_targetdef %>%
  ggplot(aes(x = zPrimeRecogRT_trim, y = zTargetRT_trim, 
             group = PrimeCondition, color = PrimeCondition)) +
  geom_smooth(method = "lm", se = FALSE, size = 1)+
  facet_wrap(~PrimeCondition, nrow = 2)+
    xlab("z-RT to Demask Prime") + ylab ("z-RT to Demask Target")+ 
  ggtitle("YA: Effect of Prime on Retrieving Target")  +
theme_hc() +
scale_color_manual(values = c( "darkorange1", "red",
                              "dodgerblue3", "springgreen3"))+
  theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5),
                  axis.text.x = element_text(size = rel(1)),
         strip.text.x = element_text(face = "bold", size = rel(1.4)))
@



\section {Plotting Raw Data}
\subsection {Model 1}
<<fig=TRUE>>=
library(ggplot2)
library(ggthemes)

mainplot = primewith_final_z %>%
  ggplot(aes(x =zPrimeRecogRT_trim , y = Accuracy, 
             group = factor(Subject))) +
  geom_smooth(method = "lm", se = FALSE, color = "darkolivegreen4", size = 0.5)+
  guides(color = FALSE)+
    xlab("z-RT to Demask Prime") + ylab ("Mean Target Accuracy")+ 
  ggtitle("YA: Target Accuracy by Prime Demasking RT")+
theme_few() +
  ylim(0,1) +
    theme(axis.text = element_text(face = "bold", size = rel(1.2)),
          axis.title = element_text(face = "bold", size = rel(1.2)),
          legend.title = element_text(face = "bold", size = rel(1.2)),
          plot.title = element_text(face = "bold", size = rel(1.2), hjust = .5))
mainplot + stat_smooth(aes(group = 1), method = "lm", color = "red")

@

\subsection {Model 2}
<<fig=TRUE>>=
fixed.frame <- 
  data.frame(expand.grid(zPrimeRecogRT_trim = seq(-3,3,0.5),
                         PrimeCondition = c("B", "P", "R", "U")))%>%
  mutate(pred = predict(RTprime_acc_model_2, newdata = ., re.form = NA))

fixed.frame %>%
  ggplot(aes(x = zPrimeRecogRT_trim, y = pred, color = PrimeCondition)) +
    geom_line(size = 1) + 
    xlab("z-RT to Demask Prime") + ylab ("Mean Target Accuracy")+ 
  ggtitle("Model Fit: Target Accuracy by Prime Demasking RT")+
theme_few() +
    theme(axis.text = element_text(face = "bold", size = rel(1.2)),
          axis.title = element_text(face = "bold", size = rel(1.2)),
          legend.title = element_text(face = "bold", size = rel(1.2)),
          plot.title = element_text(face = "bold", size = rel(1.2), hjust = .5))
@

\subsection {Model 2: Raw data}
<<fig=TRUE>>=

primeplot = primewith_final_z %>%
  mutate(PrimeType = factor(PrimeCondition, 
                    levels = unique(PrimeCondition),
                    labels = c("Both Prime", "Phonological Prime", 
                               "Semantic Prime", "Unrelated Prime")))%>%
  ggplot(aes(x = zPrimeRecogRT_trim, y = Accuracy, 
             group = factor(Subject))) +
  geom_smooth(method = "lm", se = FALSE, color = "darkolivegreen4", size = 0.5)+
  facet_wrap(~PrimeCondition)+
    xlab("z-RT to Demask Prime") + ylab ("Mean Target Accuracy")+ 
  ggtitle("YA: Target Retrieval Accuracy by \nPrime Demasking RT & Prime Condition")+
theme_hc() +
    theme(axis.text = element_text(face = "bold", size = rel(1.2)),
          axis.title = element_text(face = "bold", size = rel(1.2)),
          legend.title = element_text(face = "bold", size = rel(1.2)),
                   strip.text.x = element_text(face = "bold", size = rel(1.4)),
          plot.title = element_text(face = "bold", size = rel(1.2), hjust = .5))

primeplot + stat_smooth(aes(group = PrimeCondition), method = "lm", color = "red")
@

\subsection {Model 2: Raw data: No subject lines}
<<fig=TRUE>>=

primewith_final_z$primefac = ordered(as.factor(as.character(primewith_final_z$PrimeCondition)), levels = c("B", "R", "P", "U"))

primewith_final_z %>%
  mutate(PrimeType = factor(primefac, levels = unique(primefac),
                    labels = c("Both","Semantic", "Phonological",
                                "Unrelated")))%>%
  ggplot(aes(x = zPrimeRecogRT_trim, y = Accuracy, 
             group = PrimeType, color = PrimeType)) +
  geom_smooth(method = "lm", se = FALSE)+
    xlab("") + ylab ("Mean Target Accuracy")+ 
  ggtitle("Experiment 3")+
theme_few() +
scale_color_manual(values = c( "lightsalmon", "red",
                               "paleturquoise3","lightgreen"))+  
  ggtitle("Experiment 3") +
  theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5, size = rel(1)),
         axis.text.x = element_text(face = "bold", size = rel(1.2)))
@


\subsection {Target RT Model 2: Raw data: No subject lines}
<<fig=TRUE>>=

primewith_final_z %>%
  mutate(PrimeType = factor(primefac, levels = unique(primefac),
                    labels = c("Both","Semantic", "Phonological",
                                "Unrelated")))%>%
  ggplot(aes(x = zPrimeRecogRT_trim, y = zTargetRecogRT_trim, 
             group = PrimeType, color = PrimeType)) +
  geom_smooth(method = "lm", se = FALSE, size = 1)+
 # ylim(-0.5,0.5)+
  #facet_wrap(~PrimeCondition, nrow = 1)+
    xlab("z-RT to Demask Target") + ylab ("z-RT to Demask Target")+ 
theme_few() +
scale_color_manual(values = c( "lightsalmon", "red",
                               "paleturquoise3","lightgreen"))+  
  ggtitle("Experiment 3") +
  theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5, size = rel(1)),
         axis.text.x = element_text(face = "bold", size = rel(1.2)))
@

\subsection {Target RT Model 1}
<<fig=TRUE>>=

targetRT_rmisc = Rmisc::summarySE(primewith_final_z, 
                      measurevar = "zTargetRecogRT_trim",
                      groupvars = c("PrimeCondition"))
library(ggplot2)
library(ggthemes)
targetRT_rmisc %>% mutate(`Prime Condition` = factor(PrimeCondition, 
                                                 levels = unique(PrimeCondition),
                    labels = c("Both", "Phonological", 
                               "Semantic", "Unrelated"))) %>%
ggplot(aes(x = `Prime Condition`, 
           y = zTargetRecogRT_trim, fill = `Prime Condition`))+
 geom_bar(stat = "identity", position = "dodge", 
          width = 0.5)+
  geom_errorbar(aes(ymin = zTargetRecogRT_trim - se, ymax = zTargetRecogRT_trim + se),
                width=.05, position=position_dodge(.5)) +
  theme_few()+
  guides (fill = FALSE)+
  scale_fill_gdocs()+
  xlab("Prime Condition") + ylab("Mean Target Demasking RT") + 
  ggtitle("Target Demasking RT by Prime Condition") +
    theme(axis.text = element_text(face = "bold", size = rel(1.2)),
          axis.title = element_text(face = "bold", size = rel(1.2)),
          legend.title = element_text(face = "bold", size = rel(1.2)),
          plot.title = element_text( size = rel(1.4), hjust = .5))
@



\section {Looking at LAG}

<<>>=
PrimeRetrieval = PrimeRetrieval %>% arrange(Subject, Trial)
d = PrimeRetrieval
## Creating a lag variable
d = d %>% mutate(target_lag_1 = lag(Accuracy),
                 targetRT_lag_1 = lag(RTrecogniseTarget)) 

## Ensuring lag is being computed correctly
for (i in 1:(nrow(d)-1)){
  index_0 = i
  index_1 = i+1
  
  ## Assigning NA to the first data point for each subject
  if(d[index_0,3] > d[index_1,3]){
    d[index_1,24] = NA
    d[index_1,25] = NA

  }
  
}

write.csv(d, file = "lag_target.csv")

d$target_lag_1 = as.factor(d$target_lag_1)
lag_model = glmer(data = d, 
                          PrimeFirstResp_ACC ~ target_lag_1 + 
                            (1|Subject) + (1|Stimuli2), family = "binomial" , 
    control=glmerControl(optimizer="bobyqa",
            optCtrl=list(maxfun=1000000)))

summary(lag_model)
car::Anova(lag_model)

lag_model2 = glmer(data = d, 
                          PrimeFirstResp_ACC ~ I(targetRT_lag_1/1000) + 
                            (1|Subject) + (1|Stimuli2), family = "binomial" , 
    control=glmerControl(optimizer="bobyqa",
            optCtrl=list(maxfun=1000000)))

summary(lag_model2)
car::Anova(lag_model2)
@

\subsection {Raw Data: Lagged Accuracy}

<<>>=
#  since finaldata has several missing trials -- need 704 have 662, ANOVA is probably not the best idea -- thus, we run a linear model
d$PrimeRet = ifelse(d$PrimeFirstResp_ACC == "Retrieved", 1,0)
lag_agg_prime_ya= Rmisc::summarySE(d, 
                      measurevar = "PrimeRet",
                      groupvars = c("target_lag_1"))

lag_agg_prime_ya$target_lag_1 = as.factor(lag_agg_prime_ya$target_lag_1)
library(ggplot2)
library(ggthemes)
lag_agg_prime_ya %>% mutate(
                    TargetRet = factor(target_lag_1, 
                                        levels = unique(target_lag_1),
                    labels = c("T Not Retrieved", " T Retrieved")))%>%
  ggplot(aes(x = TargetRet, y = PrimeRet)) +  
  geom_bar(stat = "identity", position = "dodge", width = 0.5)+
   geom_errorbar(aes(ymin = PrimeRet - ci, 
                     ymax = PrimeRet + ci),
                width=.05, position=position_dodge(.5)) +
  theme_few()+
  scale_fill_wsj()+
       xlab("Prime Condition") + ylab("Mean Target Accuracy") + 
ggtitle("YA: Target Retrieval ~ \nPrime Retrieval x Prime Condition") +
  theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5),
         strip.text.x = element_text(face = "bold", size = rel(1.4)))
@
\subsection{Proportions}
<<>>=
library(dplyr)

d = d %>% filter(!is.na(target_lag_1))
d$target_lag_1 = as.numeric(as.character(d$target_lag_1))

lag_acc = group_by(d) %>%
  summarise_at(vars(PrimeRet, target_lag_1), mean)

lag_acc = group_by(d, Subject, target_lag_1) %>%
  summarise(lagrettrials = n())

conditional_acc = group_by(d, Subject, 
                           target_lag_1, PrimeRet) %>%
  summarise(trials = n())

merge_acc = merge(conditional_acc, lag_acc, 
                  by = c("Subject", "target_lag_1"))
merge_acc$prop = merge_acc$trials/merge_acc$lagrettrials
@

\subsection {ANOVA}

In this section, we perform a repeated measures ANOVA on our data, to see if we are indeed seeing a difference in the proportion of unsuccessful trials for failed and successful cued recall. 

<<>>=

merge_acc$Subject = 
  as.factor(as.character(merge_acc$Subject))
merge_acc$target_lag_1 = 
  as.factor(as.character(merge_acc$target_lag_1))
merge_acc$PrimeRet = 
  as.factor(as.character(merge_acc$PrimeRet))

cond_aov = aov(data = merge_acc, 
        prop ~ target_lag_1*PrimeRet +
        Error(Subject/(target_lag_1*PrimeRet)))
summary(cond_aov)
@

The ANOVA output tells us that the interaction term is not signiificant. We will next see this in a figure, to better understand our data.

\subsection {Conditional Figure}

<<>>=
cond_figure = Rmisc::summarySE(merge_acc, 
                        measurevar = "prop",
                        groupvars = c("target_lag_1", 
                                      "PrimeRet"))

library(ggplot2)
library(ggthemes)
condfigure_plot = cond_figure %>% mutate(LagRet = factor(target_lag_1, 
                      levels = unique(target_lag_1),
                    labels = c("Failed Previous Retrieval", 
                               "Successful Previous Retrieval")),
                    `Prime Retrieval` = factor(PrimeRet,
                          levels = unique(PrimeRet),
                       labels = c("Failed Next Prime Retrieval", 
                            "Successful Next Prime Retrieval")))%>%
ggplot(aes(x = LagRet, y = prop, 
           fill = `Prime Retrieval`, group = `Prime Retrieval`))+
 geom_bar(stat = "identity", position = "dodge", width = 0.7)+
  geom_errorbar(aes(ymin=prop - ci, ymax=prop + ci), 
             width=.1, color = "gray26", 
             position = position_dodge(0.7))+
 theme_few()+
  scale_fill_wsj()+
    xlab("Previous Target Recall Accuracy") + ylab("Mean Proportion of Trials") + 
  ggtitle("Prime Retrieval Accuracy 
          as a function of Previous Target Accuracy")  +
   theme(axis.text = element_text(face = "bold", size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
          plot.title = element_text(face = "bold", 
                  size = rel(1.2), hjust = .5),
         strip.text.x = element_text(face = "bold", size = rel(1.4)))
condfigure_plot
@

\subsection {LMER}

<<>>=
participant_acc = group_by(d, Subject) %>%
  summarise_at(vars(PrimeRet, target_lag_1), mean)

participant_acc$MeanAcc = (participant_acc$PrimeRet + 
                          participant_acc$target_lag_1)/2

colnames(participant_acc) = c("Subject", "PrimeRetAcc", "TargetLagAcc", "MeanAcc")

merge_acc = merge(merge_acc, participant_acc[,c(1,2,3,4)], 
                       by = c("Subject"))
library(lme4)
library(lmerTest)
lagmodel_acc = lmer(data = merge_acc, 
                 prop ~ target_lag_1*PrimeRet*MeanAcc +
                   (1|Subject))
summary(lagmodel_acc)
@

\subsection {Raw Data: Lagged RT}

<<>>=
library(ggplot2)
library(ggthemes)
lagplot = d %>% 
  ggplot(aes(x = targetRT_lag_1, y = PrimeRet, 
             group = factor(Subject))) +
  geom_smooth(method = "lm", se = FALSE, 
              color = "darkolivegreen4", size = 0.5)+
    xlab("z-RT to Demask Target on Trial 1") + ylab ("Mean Prime Accuracy on Trial 1")+ 
  ggtitle("YA: Lagged Model")+
theme_hc() +
    theme(axis.text = element_text(face = "bold", size = rel(1.2)),
          axis.title = element_text(face = "bold", size = rel(1.2)),
          legend.title = element_text(face = "bold", size = rel(1.2)),
                   strip.text.x = element_text(face = "bold", size = rel(1.4)),
          plot.title = element_text(face = "bold", size = rel(1.2), hjust = .5))

lagplot + stat_smooth( aes(group = 1), method = "lm", color = "red")
@

\section {z-RT Lag Demasking Analysis}

<<>>=
library(dplyr)
d_firsttrim = subset(d, d$targetRT_lag_1 > 300)

## aggregate per subject all IVs and DVs
meanRT = group_by(d_firsttrim, Subject) %>%
  summarise_at(vars(targetRT_lag_1), mean)
colnames(meanRT) = c("Subject", "MeanTargetLagRT")

sdRT = group_by(d_firsttrim, Subject) %>%
  summarise_at(vars(targetRT_lag_1), sd)
colnames(sdRT) = c("Subject", "sdTargetLagRT")

RT_agg = merge(meanRT, sdRT, by = "Subject")

## merge aggregate info with long data
d_z = merge(d_firsttrim, RT_agg, by = "Subject", all.x = T)

## person and grand-mean centered scores using original and aggregate
library(dplyr)
d_z = d_z %>% mutate(zTargetLagRT = (targetRT_lag_1 - 
                                       MeanTargetLagRT)/sdTargetLagRT)
                 
## checking: subject level means should be zero

sub_pic = group_by(d_z, Subject) %>%
  summarise_at(vars(zTargetLagRT), mean)

@

\section {Trimming z-RTs}

<<>>=
d_z_trimmed = subset(d_z,d_z$zTargetLagRT < 3 & 
                                  d_z$zTargetLagRT > -3)
@

\section {Repeating z-scoring}

<<>>=
## aggregate per subject all IVs and DVs
meanRT = group_by(d_z_trimmed, Subject) %>%
  summarise_at(vars(targetRT_lag_1), mean)
colnames(meanRT) = c("Subject", "MeanTargetLagRT_trim")

sdRT = group_by(d_z_trimmed, Subject) %>%
  summarise_at(vars(targetRT_lag_1), sd)
colnames(sdRT) = c("Subject", "sdTargetLagRT_trim")

RT_agg = merge(meanRT, sdRT, by = "Subject")

## merge aggregate info with long data
d_final_z = merge(d_z_trimmed,  RT_agg, by = "Subject", all.x = T)

## person and grand-mean centered scores using original and aggregate
library(dplyr)
d_final_z = d_final_z %>% mutate(zTargetLagRT_trim = 
            (targetRT_lag_1 - MeanTargetLagRT_trim)/sdTargetLagRT_trim)
                 
## checking: subject level means should be zero

sub_pic = group_by(d_final_z, Subject) %>%
  summarise_at(vars(zTargetLagRT_trim), mean)

@

\subsection{zRT Lag Model}

<<>>=

lag_model3 = glmer(data = d_final_z, 
                          PrimeFirstResp_ACC ~ zTargetLagRT_trim  + 
                            (1|Subject) + (1|Stimuli2), family = "binomial" , 
    control=glmerControl(optimizer="bobyqa",
            optCtrl=list(maxfun=1000000)))

summary(lag_model3)
car::Anova(lag_model3)
@

\subsection {zRT Data: Lagged zRT}

<<>>=
#
library(ggplot2)
library(ggthemes)
lagplot2 = d_final_z %>% 
  ggplot(aes(x = zTargetLagRT_trim, y = PrimeRet, 
             group = factor(Subject))) +
  geom_smooth(method = "lm", se = FALSE, 
              color = "darkolivegreen4", size = 0.5)+
    xlab("z-RT to Demask Target on Trial 1") + ylab ("Mean Prime Accuracy on Trial 2")+ 
  ggtitle("YA: Lagged Model")+
theme_hc() +
    theme(axis.text = element_text(face = "bold", size = rel(1.2)),
          axis.title = element_text(face = "bold", size = rel(1.2)),
          legend.title = element_text(face = "bold", size = rel(1.2)),
                   strip.text.x = element_text(face = "bold", size = rel(1.4)),
          plot.title = element_text(face = "bold", size = rel(1.2), hjust = .5))

lagplot2 + stat_smooth( aes(group = 1), method = "lm", color = "red")
@

\section {Topic and Proper Names}

\subsection {Topics by AgeGroup}

<<>>=
PrimeRetrieval <- read.csv("CompleteYAOA_FINAL.csv", 
                           header = TRUE, sep = ",")

stimuli = read.csv("TOT_stimuli.csv", header = TRUE, sep = ",")

merged_primeretrieval = merge(PrimeRetrieval, stimuli, by = c("Stimuli2"))

topic_acc = group_by(merged_primeretrieval, AgeGroup, ID, Topic) %>%
  summarise_at(vars(Accuracy), mean)

topic_rmisc = Rmisc::summarySE(topic_acc, 
                               measurevar = "Accuracy",
                               groupvars = c("AgeGroup", "Topic"))
library(ggplot2)
library(ggthemes)
 topic_rmisc %>% 
  ggplot(aes(x = Topic, y = Accuracy, group = AgeGroup, fill = AgeGroup)) + 
 geom_bar(stat = "identity", position = "dodge", width = 0.5)+
   geom_errorbar(aes(ymin = Accuracy - se, ymax = Accuracy + se),
                width=.05, position=position_dodge(.5)) +
    theme_few()+
   xlab("Topic") + ylab("Mean Target Retrieval Accuracy") + 
  ggtitle("")  +
   theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5),
         strip.text.x = element_text(face = "bold", size = rel(1.4)))
 
 topic_acc$ID = as.factor(topic_acc$ID)
 topic_aov = aov(data = topic_acc, Accuracy ~ AgeGroup*Topic + 
                   Error(ID/Topic))
 summary(topic_aov)


@

\subsection {POS by AgeGroup}

<<>>=
pos_acc = group_by(merged_primeretrieval, AgeGroup, ID, POS) %>%
  summarise_at(vars(Accuracy), mean)
 
pos_acc$Proper = ifelse(pos_acc$POS == "ProperName", "ProperName", "Word") 

pos_rmisc = Rmisc::summarySE(pos_acc, 
                               measurevar = "Accuracy",
                               groupvars = c("AgeGroup", "POS"))
library(ggplot2)
library(ggthemes)
 pos_rmisc %>% 
  ggplot(aes(x = POS, y = Accuracy, group = AgeGroup, fill = AgeGroup)) + 
 geom_bar(stat = "identity", position = "dodge", width = 0.5)+
   geom_errorbar(aes(ymin = Accuracy - se, ymax = Accuracy + se),
                width=.05, position=position_dodge(.5)) +
    theme_few()+
   xlab("Proper Name or Word") + ylab("Mean Target Retrieval Accuracy") + 
  ggtitle("")  +
   theme(axis.text = element_text(size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
         plot.title = element_text(hjust = .5),
         strip.text.x = element_text(face = "bold", size = rel(1.4)))
 
 pos_acc$ID = as.factor(pos_acc$ID)
 pos_aov = aov(data = pos_acc, Accuracy ~ AgeGroup*POS + 
                   Error(ID/POS))
 summary(pos_aov) 
@

\section {Item Analyses}

\subsection {Prime And Target Accuracy}
<<>>=
library(dplyr)

agg_item_condition <-  group_by(PrimeRetrieval, Stimuli2, PrimeCondition)%>%
    summarise_at(vars(Accuracy), mean)

agg_item_condition$Stimuli2 <- as.factor(agg_item_condition$Stimuli2)
agg_item_condition$PrimeCondition <- as.factor(agg_item_condition$PrimeCondition)

agg_item_prime = group_by(PrimeRetrieval, Stimuli2, PrimeCondition) %>%
   summarise_at(vars(PrimeFirstResp_ACC), mean)
## target accuracy anova

prime_aov = aov(data = agg_item_condition, Accuracy ~ PrimeCondition + 
                                        Error(Stimuli2/PrimeCondition))
summary(prime_aov)

## prime accuracy anova
agg_item_prime$Stimuli2 = as.factor(agg_item_prime$Stimuli2)
primeaccuracy_aov = aov(data = agg_item_prime, 
                        PrimeFirstResp_ACC ~ PrimeCondition + 
                                        Error(Stimuli2/PrimeCondition))
summary(primeaccuracy_aov)

## accounting for mean accuracy

item_acc = group_by(PrimeRetrieval, Stimuli2) %>%
  summarise_at(vars(Accuracy, PrimeFirstResp_ACC), mean)

item_acc$MeanAcc = (item_acc$Accuracy + 
                          item_acc$PrimeFirstResp_ACC)/2

colnames(item_acc) = c("Stimuli2", "TargetAcc", "PrimeAcc", "MeanAcc")

PrimeRetrieval = merge(PrimeRetrieval, item_acc[,c(1,3,4)], 
                       by = c("Stimuli2"))
@

<<>>=
 
 @

\section {M Turk Rating Data}

\subsection {Item Ratings Wide}

<<>>=
# itemsratings = read.csv("Abhilasha_TOT_FINAL.csv", header = TRUE, sep = ",")
# 
# meanratings = group_by(itemsratings, Target, Procedure, PrimeType) %>%
#   summarise_at(vars(Rating), mean)
# #write.csv(meanratings, file = "Abhilasha_item_long.csv")
# 
# ## convert to wide
# 
# meanratings_wide = spread(meanratings, Procedure, Rating)

#write.csv(meanratings_wide, file = "Abhilasha_item_wide.csv")
@

\subsection *{Calculating item level accuracies}

<<>>=
itemratings= read.csv("Abhilasha_item_wide.csv", 
                             header = TRUE, sep = ",")

main = PrimeRetrieval

main_item = merge(main, itemratings, by = c("Stimuli2", "Target"))
main_item = dplyr::arrange(main_item, Subject, Stimuli2, PrimeType)

## but we also need item-level accuracy data
library(dplyr)
item_acc = group_by(main_item, Stimuli2) %>%
  summarise_at(vars(Accuracy), mean)
colnames(item_acc) = c("Stimuli2", "ItemAcc")

main_item = merge(main_item, item_acc, by = c("Stimuli2"))
main_item = dplyr::arrange(main_item, Subject, Stimuli2, PrimeType)
## Now we run an HLM for each prime condition separately
@

\subsection *{Predicting Accuracy Using Rating}

<<>>=
Phon = main_item %>% filter(PrimeCondition == "P" & 
                                  PrimeType == "Phonological")
                              
Sem = main_item %>% filter(PrimeCondition == "R" & 
                             PrimeType == "Semantic")
Both_Phon = main_item %>% filter(PrimeCondition == "B" & 
                                   PrimeType == "Both")
Both_Sem = main_item %>% filter(PrimeCondition == "B" & 
                                  PrimeType == "Both")
@

\subsubsection *{Models}
\subsubsection *{Models with Only Rating}

<<>>=
library(lme4)

phon_model = glmer(data = Phon, Accuracy ~ SoundRating + 
                     (1|Subject), family = "binomial")
summary(phon_model)

sem_model = glmer(data = Sem, Accuracy ~ MeaningRating  + 
                     (1|Subject), family = "binomial")
summary(sem_model)

both_sem_model = glmer(data = Both_Sem, Accuracy ~  MeaningRating + 
                     (1|Subject), family = "binomial", 
    control=glmerControl(optimizer="bobyqa",
            optCtrl=list(maxfun=100000)))
summary(both_sem_model)

both_phon_model = glmer(data = Both_Phon, Accuracy ~ SoundRating  + 
                     (1|Subject), family = "binomial", 
    control=glmerControl(optimizer="bobyqa",
            optCtrl=list(maxfun=100000)))
summary(both_phon_model)

@

\subsection* {Plotting Model Fits: Rating Only}

\subsubsection*{Phonological}

<<>>=
fixed.frame <-
  data.frame(
    expand.grid(
      # here, you add values for your time variable and predictors
      SoundRating = seq(1,7,1))) 
fixed.frame$pred = predict(phon_model, newdata = fixed.frame, re.form = NA)
fixed.frame$odds = exp(fixed.frame$pred)
fixed.frame$prob = fixed.frame$odds/(1+fixed.frame$odds)

a = fixed.frame %>%
  ggplot(aes(x = SoundRating, y = prob)) +
    geom_line(size = 1, color = "forestgreen") +
        labs(x = "Sound Rating for Phon Prime:Target", 
             y = "Predicted Probabilities for Accuracy",
         title = "Effect of Prime Rating on Accuracy in 
         Phonological Condition") +
  theme_few()+
  ylim(0,0.40)+
    scale_color_colorblind() +
    theme(axis.text = element_text(face = "bold", size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
          plot.title = element_text(face = "bold", size = rel(1.2), hjust = .5))
@


\subsubsection*{Semantic}

<<>>=
fixed.frame <-
  data.frame(
    expand.grid(
      # here, you add values for your time variable and predictors
      MeaningRating = seq(1,7,1))) 
fixed.frame$pred = predict(sem_model, newdata = fixed.frame, re.form = NA)
fixed.frame$odds = exp(fixed.frame$pred)
fixed.frame$prob = fixed.frame$odds/(1+fixed.frame$odds)

b = fixed.frame %>%
  ggplot(aes(x = MeaningRating, y = prob)) +
    geom_line(size = 1, color = "red") +
        labs(x = "Meaning Rating for Sem Prime:Target", 
             y = "Predicted Probabilities for Accuracy",
         title = "Effect of Prime Rating on Accuracy in 
         Semantic Condition") +
  ylim(0,0.40)+
  theme_few()+
    scale_color_colorblind() +
    theme(axis.text = element_text(face = "bold", size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
          plot.title = element_text(face = "bold", size = rel(1.2), hjust = .5))
@

\subsubsection*{Both_Sem}

<<>>=
fixed.frame <-
  data.frame(
    expand.grid(
      # here, you add values for your time variable and predictors
      MeaningRating = seq(1,7,1))) 
fixed.frame$pred = predict(both_sem_model, 
                           newdata = fixed.frame, re.form = NA)
fixed.frame$odds = exp(fixed.frame$pred)
fixed.frame$prob = fixed.frame$odds/(1+fixed.frame$odds)

c = fixed.frame %>%
  ggplot(aes(x = MeaningRating, y = prob)) +
    geom_line(size = 1, color = "red") +
        labs(x = "Meaning Rating for Both Prime:Target", 
             y = "Predicted Probabilities for Accuracy",
         title = "Effect of Prime Rating on Accuracy in 
         Both Condition") +
  ylim(0,0.40)+
  theme_few()+
    scale_color_colorblind() +
    theme(axis.text = element_text(face = "bold", size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
          plot.title = element_text(face = "bold", size = rel(1.2), hjust = .5))
@

\subsubsection*{Both_Phon}

<<>>=
fixed.frame <-
  data.frame(
    expand.grid(
      # here, you add values for your time variable and predictors
      SoundRating = seq(1,7,1))) 
fixed.frame$pred = predict(both_phon_model, 
                           newdata = fixed.frame, re.form = NA)
fixed.frame$odds = exp(fixed.frame$pred)
fixed.frame$prob = fixed.frame$odds/(1+fixed.frame$odds)

d = fixed.frame %>%
  ggplot(aes(x = SoundRating, y = prob)) +
    geom_line(size = 1, color = "forestgreen") +
        labs(x = "Sound Rating for Both Prime:Target", 
             y = "Predicted Probabilities for Accuracy",
         title = "Effect of Prime Rating on Accuracy in 
         Both Condition") +
  theme_few()+
  ylim(0,0.40)+
    scale_color_colorblind() +
    theme(axis.text = element_text(face = "bold", size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
          plot.title = element_text(face = "bold", size = rel(1.2), hjust = .5))
@

<<>>=
library(gridExtra)
grid.arrange(a,b,d,c)
@

\subsection *{Models with Rating and Average Performance}

<<>>=
library(lme4)

phon_model_2 = glmer(data = Phon, Accuracy ~ SoundRating*ItemAcc + 
                     (1|Subject), family = "binomial")
summary(phon_model_2)

sem_model_2 = glmer(data = Sem, Accuracy ~ MeaningRating*ItemAcc  + 
                     (1|Subject), family = "binomial")
summary(sem_model_2)

both_phon_model_2 = glmer(data = Both_Phon, Accuracy ~ SoundRating*ItemAcc  + 
                     (1|Subject), family = "binomial")
summary(both_phon_model_2)


both_sem_model_2 = glmer(data = Both_Sem, Accuracy ~ MeaningRating*ItemAcc  + 
                     (1|Subject), family = "binomial",
                     control=glmerControl(optimizer="bobyqa",
         optCtrl=list(maxfun=100000)))
summary(both_sem_model_2)

## seems that ratings have an overall effect on accuracy, but not above and beyond the mean level accuracy of the item itself. 

@

\subsection* {Plotting Model Fits: Rating and Mean Accuracy}

\subsubsection*{Phonological}

<<>>=
fixed.frame <- Phon %>% 
  dplyr::summarise(mean = mean(ItemAcc, na.rm = T), 
            sd = sd(ItemAcc, na.rm = T))

fixed.frame <-
  data.frame(
    expand.grid(
      # here, you add values for your time variable and predictors
      SoundRating = seq(1,7,1),
       ItemAcc = c(fixed.frame$mean-fixed.frame$sd,
                     fixed.frame$mean,
                     fixed.frame$mean+fixed.frame$sd))) 

fixed.frame$pred = predict(phon_model_2, newdata = fixed.frame, re.form = NA)
fixed.frame$odds = exp(fixed.frame$pred)
fixed.frame$prob = fixed.frame$odds/(1+fixed.frame$odds)

a2 = fixed.frame %>%
mutate(ItemAccuracy = factor(ItemAcc, levels = unique(ItemAcc),
                                 labels = c("-1SD", "0SD", "1SD"))) %>%
  ggplot(aes(x = SoundRating, y = prob, color = ItemAccuracy)) +
  geom_line(size = 1) +
        labs(x = "Sound Rating", 
             y = "",
         title = "Phonological Condition (Sound Rating)") +
  theme_few()+
    theme(axis.text = element_text(face = "bold", size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
          plot.title = element_text(face = "bold", size = rel(1), hjust = .5))
@


\subsubsection*{Semantic}

<<>>=
fixed.frame <- Phon %>% 
  dplyr::summarise(mean = mean(ItemAcc, na.rm = T), 
            sd = sd(ItemAcc, na.rm = T))

fixed.frame <-
  data.frame(
    expand.grid(
      # here, you add values for your time variable and predictors
      MeaningRating = seq(1,7,1),
       ItemAcc = c(fixed.frame$mean-fixed.frame$sd,
                     fixed.frame$mean,
                     fixed.frame$mean+fixed.frame$sd))) 

fixed.frame$pred = predict(sem_model_2, newdata = fixed.frame, re.form = NA)
fixed.frame$odds = exp(fixed.frame$pred)
fixed.frame$prob = fixed.frame$odds/(1+fixed.frame$odds)

b2 = fixed.frame %>%
mutate(ItemAccuracy = factor(ItemAcc, levels = unique(ItemAcc),
                                 labels = c("-1SD", "0SD", "1SD"))) %>%
  ggplot(aes(x = MeaningRating, y = prob, color = ItemAccuracy)) +
  geom_line(size = 1) +
          labs(x = "Meaning Rating", 
             y = "",
         title = "Semantic Condition (Meaning Rating)") +
  theme_few()+
    theme(axis.text = element_text(face = "bold", size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
          plot.title = element_text(face = "bold", size = rel(1), hjust = .5))
@

\subsubsection*{Both_Sem}

<<>>=
fixed.frame <- Phon %>% 
  dplyr::summarise(mean = mean(ItemAcc, na.rm = T), 
            sd = sd(ItemAcc, na.rm = T))

fixed.frame <-
  data.frame(
    expand.grid(
      # here, you add values for your time variable and predictors
      MeaningRating = seq(1,7,1),
       ItemAcc = c(fixed.frame$mean-fixed.frame$sd,
                     fixed.frame$mean,
                     fixed.frame$mean+fixed.frame$sd))) 

fixed.frame$pred = predict(both_sem_model_2, 
                           newdata = fixed.frame, re.form = NA)
fixed.frame$odds = exp(fixed.frame$pred)
fixed.frame$prob = fixed.frame$odds/(1+fixed.frame$odds)

c2 = fixed.frame %>%
mutate(ItemAccuracy = factor(ItemAcc, levels = unique(ItemAcc),
                                 labels = c("-1SD", "0SD", "1SD"))) %>%
  ggplot(aes(x = MeaningRating, y = prob, color = ItemAccuracy)) +
  geom_line(size = 1) +
           labs(x = "Meaning Rating", 
             y = "",
         title = "Both Condition (Meaning Rating)") +
  theme_few()+
    theme(axis.text = element_text(face = "bold", size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
          plot.title = element_text(face = "bold", size = rel(1), hjust = .5))
@

\subsubsection*{Both_Phon}

<<>>=
fixed.frame <- Phon %>% 
  dplyr::summarise(mean = mean(ItemAcc, na.rm = T), 
            sd = sd(ItemAcc, na.rm = T))

fixed.frame <-
  data.frame(
    expand.grid(
      # here, you add values for your time variable and predictors
      SoundRating = seq(1,7,1),
       ItemAcc = c(fixed.frame$mean-fixed.frame$sd,
                     fixed.frame$mean,
                     fixed.frame$mean+fixed.frame$sd))) 

fixed.frame$pred = predict(both_phon_model_2, 
                           newdata = fixed.frame, re.form = NA)
fixed.frame$odds = exp(fixed.frame$pred)
fixed.frame$prob = fixed.frame$odds/(1+fixed.frame$odds)

d2 = fixed.frame %>%
mutate(ItemAccuracy = factor(ItemAcc, levels = unique(ItemAcc),
                                 labels = c("-1SD", "0SD", "1SD"))) %>%
  ggplot(aes(x = SoundRating, y = prob, color = ItemAccuracy)) +
  geom_line(size = 1) +
         labs(x = "Sound Rating", 
             y = "",
         title = "Both Condition (Sound Rating)") +
  theme_few()+
    theme(axis.text = element_text(face = "bold", size = rel(1)),
          axis.title = element_text(face = "bold", size = rel(1)),
          legend.title = element_text(face = "bold", size = rel(1)),
          plot.title = element_text(face = "bold", size = rel(1), hjust = .5))
@

<<>>=
library(gridExtra)
library(grid)
grid.arrange(a2,b2,d2,c2, 
            top=textGrob("Target Retrieval Accuracy as a function of\nPrime-Target Association Ratings", 
                                      gp=gpar(fontsize=20)),
             left = textGrob("Predicted Probabilities for Target Retrieval Accuracy", rot = 90, vjust = 1, gp = gpar(fontsize = 15)))
@

\section {MTurk Covariate Analyses}

<<>>=
itemratings= read.csv("Abhilasha_item_wide.csv", 
                             header = TRUE, sep = ",")

main = PrimeRetrieval

main = main %>% filter(PrimeCondition %in% c("P", "R"))
main_item = merge(main, itemratings, 
                  by = c("Stimuli2", "PrimeCondition"))
main_item = dplyr::arrange(main_item, ID, Stimuli2, PrimeType)

## Impacting Ret/NotRet

main_item$PrimeFirstResp_ACC = as.factor(main_item$PrimeFirstResp_ACC)
m_young_prime2 = lme4::glmer(data = main_item, Accuracy ~ 
                   PrimeFirstResp_ACC*PrimeCondition  + PrimeAcc +
                             MeaningRating +
                           (1|Subject) + (1|Stimuli2),
                          family = "binomial",
                          control=glmerControl(optimizer="bobyqa",
            optCtrl=list(maxfun=100000)))

summary(m_young_prime2)
options(contrasts = c("contr.sum","contr.poly"))
car::Anova(m_young_prime2)
anova(m_young_prime2)
#sjPlot::plot_model(m_young_prime2, type = "int")
@

\section {Item Difficulty}

<<>>=

@




\end{document}